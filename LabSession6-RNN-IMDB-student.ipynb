{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "",
  "signature": "sha256:b7807715ce8996bfe74b5b037a20587cb950128851d6165f4083bfb2798ab797"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "nbpresent": {
       "id": "18cde020-8365-4923-8590-7d111b4a41f8"
      }
     },
     "source": [
      "# ELU 502 Deep learning  IMT Atlantique -- Lab session 6\n",
      "Max Sobroza, Pierre Tandeo - session: 1h20+3h\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "nbpresent": {
       "id": "797413a2-61f3-40e6-a8f0-242b28d4e090"
      }
     },
     "source": [
      "### Objectives: Perform sentiment analysis classification on *IMDB dataset* exploring multiples architectures of recurrent neural networks (RNN, LSTM, BiLSTM, ...) and transfer learning from word embeddings vectors to achieve better results on a NLP (Natural Language Processing) task.\n",
      "\n",
      "Hint: See the documentation of Keras for implementation details."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color='blue'> What is IMDB ?</font>\n",
      "\n",
      "- It is a website that contains several movies reviews from users\n",
      "\n",
      "[Imdb's site](https://www.imdb.com)\n",
      "\n",
      "Considering that we have only two classes of reviews (<font color='blue'>positive</font> or <font color='red'> negative </font>). Could you predict the labels of reviews based only on text content of these reviews ?\n",
      "\n",
      "**Review \\#1**\n",
      "\n",
      "*Quite simply, the finest gangster film ever made. No doubt about it, this a spectacular viewing experience. The acting along with the storyline makes this film a genuine masterpiece. The film covers a wide spectrum of genre keeping the viewer entertained throughout. TOP CLASS!*\n",
      "\n",
      "**Review \\#2**\n",
      "\n",
      "*This movie is like football, people only watch it because the think its 'cool' or 'popular', but really it is the most dreary repetitive and slow film i have had the displeasure in viewing. How this film grew to be such a ''great'' i do not know, bu ti know that it shouldn't be, Shawshank Redemption may not deserve to be second best film ever, but at least it is worthy of being where it is and is certainly a better film than any of the Godfathers.\n",
      "So please consider this when voting, the Godfather is poorly directed, badly scripted, crudely acted and most importantly is, quite frankly boring and wearisome.*\n",
      "\n",
      "**Review \\#3**\n",
      "\n",
      "*Great Book... Slightly above average movie (so sad)\n",
      "The book is awesome, one of the best books ever. Sadly the movie is weak, and fails to portrait the true essence of the characters, what's so great about the book is that you're able to know and understand the background stories, therefore you identify with the characters behavior to the point where you even forget they're mobsters!! however in the movie many minor and irrelevant scenes take too much time, time that could be used to go a little deeper into the characters, and what's even worst is the total disregard to important passages of the book which didn't even make the movie, or if they did, they were over-synthesized. I don't think I'm the only one that really loved the book, but was sadly disappointed by the movie, still is a movie worth watching, but if you really want to enjoy a great story you should read the book!!*\n",
      "\n",
      "\n",
      "Sometimes, even for us it is complicated to perform this task. In this lab session, we will create an algorithm that does these predictions automatically with more than 82.0% of accuracy. The state-of-the art methods achieves on this task (about 87.0% to 90.0%). Examples of application of this task are human dialogue sentiment identification, user opinion of product reviews, chat bots language understanding and/or Twitter language understanding."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "nbpresent": {
       "id": "ec0f8430-76a1-475d-a360-8f93ab4f2732"
      }
     },
     "source": [
      "Now it is your turn and good luck!\n",
      "\n",
      "First, we need to download and import the IMDB dataset from Keras."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import keras\n",
      "from keras.datasets import imdb\n",
      "from keras.preprocessing import sequence\n",
      "from keras.utils import np_utils\n",
      "import numpy as np\n",
      "\n",
      "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
      "                                                      num_words=None, # Number of words of the vocabulary (None=gets all words)\n",
      "                                                      skip_top=0,     # Excludes top-k frequent words\n",
      "                                                      maxlen=None,)   # Max length of sentences"
     ],
     "language": "python",
     "metadata": {
      "nbpresent": {
       "id": "2b07a011-1503-4935-8cb4-30013804a57c"
      }
     },
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "nbpresent": {
       "id": "ef32a37b-7b4d-48b6-af65-15f6d4fc2f11"
      }
     },
     "source": [
      "Differently from images, the text contains only discrete information:\n",
      "\n",
      "- Each unique word is mapped to an unique index (integer)\n",
      "- Each sentence or document contains a sequence of words (or indexes)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_index = imdb.get_word_index(path='imdb_word_index.json') # Load word vocabulary dictionary \n",
      "print('> Index of word \\\"special\\\" is {}'.format(word_index['special']))\n",
      "print('> Index of word \\\"effects\\\" is {}'.format(word_index['effects']))"
     ],
     "language": "python",
     "metadata": {
      "nbpresent": {
       "id": "51ce5a95-c7f7-4a4f-aac8-f63cccd10c47"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "> Index of word \"special\" is 315\n",
        "> Index of word \"effects\" is 299\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "nbpresent": {
       "id": "3932ee92-6e56-4848-ad3c-217fa649a1a0"
      }
     },
     "source": [
      "In the dataset loaded by Keras the preprocessing is already done: words are already tokenized and indexed.\n",
      "\n",
      "The second step is to obtain the dictionary that translates indexes (integer) to words (string)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "nbpresent": {
       "id": "1e3b1492-da1f-4c1b-82f2-97820ad210a1"
      }
     },
     "source": [
      "The reversed dictionary of *word_index* is obtained by the follow command:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index_word = dict([[v,k] for k,v in word_index.items()])\n",
      "print('> The word corresponding to the Index 315 is \\\"{}\\\"'.format(index_word[315]))\n",
      "print('> The word corresponding to the Index 299 is \\\"{}\\\"'.format(index_word[299]))"
     ],
     "language": "python",
     "metadata": {
      "nbpresent": {
       "id": "177952ae-d1ac-45d1-81fa-20361b8a48cf"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "> The word corresponding to the Index 315 is \"special\"\n",
        "> The word corresponding to the Index 299 is \"effects\"\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "nbpresent": {
       "id": "12084ea3-801c-46ca-a9c8-2442457d921f"
      }
     },
     "source": [
      "The number of unique words in the vocabulary is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('> Number of words in vocabulary: {}'.format(len(word_index)))"
     ],
     "language": "python",
     "metadata": {
      "nbpresent": {
       "id": "8eadbdf7-06fd-4d7c-bb63-fbfd1d7d4877"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "> Number of words in vocabulary: 88584\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "nbpresent": {
       "id": "5fae17c5-d856-45ea-b6c3-d01dd6dc501f"
      }
     },
     "source": [
      "Part 1) Exploring the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Transform sequences of indexes to raw text\n",
      "# If the index does not in vocabulary you need to continue without this index\n",
      "def indexes_to_text(indexes):\n",
      "    result = \"\"\n",
      "    for i in indexes:\n",
      "        if i not in index_word:\n",
      "            continue\n",
      "        try:\n",
      "            result = result+\" \"+str(index_word[i])\n",
      "        except:\n",
      "            continue\n",
      "    return result    "
     ],
     "language": "python",
     "metadata": {
      "nbpresent": {
       "id": "1c8c1351-b90b-4481-90d2-4decd3b8ad08"
      }
     },
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('> Number of training examples (x_train): {} \\n'.format(x_train.shape))\n",
      "print('> Number of training labeled examples (y_train): {} \\n'.format(y_train.shape))\n",
      "print('> First training example (indexes) is: {} \\n'.format(x_train[0]))\n",
      "print('> First training example (raw text) is: \\\"{}\\\" \\n'.format(indexes_to_text(x_train[0])))\n",
      "print('> Label of first example is: \\\"{}\\\" (positive = \\\"1\\\" and negative = \\\"0\\\")\\n'.format(y_train[0]))"
     ],
     "language": "python",
     "metadata": {
      "nbpresent": {
       "id": "418f9517-920a-4a9b-b2c2-89a3ac50107b"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "> Number of training examples (x_train): (25000,) \n",
        "\n",
        "> Number of training labeled examples (y_train): (25000,) \n",
        "\n",
        "> First training example (indexes) is: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] \n",
        "\n",
        "> First training example (raw text) is: \" the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\" \n",
        "\n",
        "> Label of first example is: \"1\" (positive = \"1\" and negative = \"0\")\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 1.1) Find the first document review (training example) that appears the words **soundtrack** and **effects** (not necessarily consecutives):\n",
      "\n",
      "Answer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CELL TO COMPLETE (~ 6 lines)\n",
      "index1 = word_index['soundtrack']\n",
      "index2 = word_index['effects']\n",
      "for review in x_train :\n",
      "    if index1 in review and index2 in review :\n",
      "        print(indexes_to_text(review))\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " the not was tom plot than taken in can as on it's good moments taken some br of entertaining believable series is far mistakes i i of you gave this so charismatic timing too regarded worse trying those in be enormously watch plot actors as example lungs br dressed to of script kill it ww who be iran all it jamie has seeing tries in giving in made to us found all begin nah film made just music even guaranteed which be mates florida for would story michel one chuck about terrific in illusion film regarded worse is over anti which be around mates tries is felt br made whom just by br though producer private tie rating know us four power tries scant fillmore to just scant fillmore regarded worse it last not is very set annoyed agrees interested this now acting play just louis comedy of sheriff attempt also message military streets br play movie version movie stagecoach not this as until on if of because too however stagecoach it boy damon has regarded worse not all against laugh read louis effects be relationship dietrich get movies name this be characters to that it theatre spin lifetime intense it yet br virgin all interesting virgin movie is courage fred not girl most br of changed really else thing danny made stagecoach it tony movie your not would effects is lasts to as utilizing are ross it by br of german words film of you of watched films he an good went br leader some br do it's life that an new characters to 8 introduction regarded it of relationship walk like trying those in kill in also an of next to all against laugh read has be you'll really commitment average polarized complexity intense it is ned not crying courage fred stagecoach it of various not time falling capote satires passionate did cut it is commune complaining quirky satires none it of violent feel like william first be grayson casting to there is france costumes to her are dressed i i of their places is stars br logo really he is over movies anything dozens but only twists regarded out involved in borg first be mates this is fighters be mates out involved in at chips tv or about facing no of extreme declares be covers but of how my to them more it of tell perhaps once i i this that is originally feel palance are romance regarded worse crime recently in same made this is locales br an details of put it fair plotted film of famous videos to trees america if likable this of vehicle to worst of feel crime talking regarded this artists br never originally movie is cadavers to guilt they made not lead like all language stagecoach would blair this match br of kidding in looked regarded is collection really earth ending forward 2 implausible they as fair surprisingly show earlier to sad once waste hit wonder think which north fear self to as involved are of every hard for stagecoach to louis can't william of violence br as lies horror in one you're broadway underdog introduction be script acting don't fan it of you'll br as on in at creating more it which is courage b this really is resurrection classical film regarded intense manage good collection ross some br of slapped odds flying that with just is imagination boys escape funny various 10 it of too louis with plus has of rest commune referenced capote to around get mitchell stagecoach movie of on hung bad same some for louis talking stagecoach in at movies various but made out movie of passionate capote talking louis in at movies along silly but about more it is soundtrack to in at preying this of guy greater stagecoach stagecoach it cuts movie ambitious who seeing go of passionate capote it cuts movie is occasional to so settings of arrives nor it for of munsters being trying better movie girl various to his they an movie settings about baldwin avoid to civilization he episodes china aren't difference dealing to infected they there's pero being knew for would stagecoach it various more it funny storm for was nothing knowledge in laughed louis me ultimately beat so once but be crash their get just of violence br as on to series such all moments she film of blind broadway ann i i of you knows there is impressive down to of impression it mind not of guy old run believable parent in table are aren't lies john br are across fans films to songs i i what poor comment this leaves only arabia br improve stagecoach to because until bunker pack we who incredibly ensues\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 1.2) Find the maximum, minimum and the average number of words per document?\n",
      "\n",
      "Answer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CELL TO COMPLETE (~ 4 lines)\n",
      "print(\"The maximum number of words in a document review is %i \" %max(map(len,x_train)))\n",
      "print(\"The minimum number of words in a document review is %i \" %min(map(len,x_train)))\n",
      "print(\"The average number of words in a document review is %1.1f \" %np.mean(map(len,x_train)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The maximum number of words in a document review is 2494 \n",
        "The minimum number of words in a document review is 11 \n",
        "The average number of words in a document review is 238.7 \n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Shows the total number of labels\n",
      "num_classes = np.max(y_train)+1\n",
      "print('> Number of classes: {}\\n'.format(num_classes))\n",
      "# We select only sequences that contain less or equal than maxlen words\n",
      "# We chosed this value because it is between max and min length words per document but it is a hyperparameter\n",
      "# We limited this value in order to take less time to process sequences\n",
      "maxlen = 500"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "> Number of classes: 2\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 1.3) What is the size of the training and test datasets before and after paddings? Why do we use paddings? What happens if the sequence length is shorter or longer than *maxlen*?\n",
      "\n",
      "Answer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We use all words of vocabulary\n",
      "max_words = len(word_index)\n",
      "print('Vectorizing sequence data...\\n')\n",
      "# Adding padding in sequences with less than max_words\n",
      "X_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
      "X_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
      "\n",
      "### CELL TO COMPLETE (print information of the last question below) (~ 6 lines)\n",
      "print(\"Before paddings the training data set contains %i reviews and %i after paddings\" %(len(x_train),len(X_train)))\n",
      "print(\"Before paddings the test data set contains %i reviews and %i after paddings\" %(len(x_test),len(X_test)))\n",
      "print(\"If the length is longer than maxlen, we cut the review after 500 words. If it's shorter, we add zeros until the length is 500.\")\n",
      "print(\"We use padddings because the input size for keras has to be the same for every input.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Vectorizing sequence data...\n",
        "\n",
        "Before paddings the training data set contains 25000 reviews and 25000 after paddings"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Before paddings the test data set contains 25000 reviews and 25000 after paddings\n",
        "If the length is longer than maxlen, we cut the review after 500 words. If it's shorter, we add zeros until the length is 500.\n",
        "We use padddings because the input size for keras has to be the same for every input.\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 2) Many-to-one sequence logistic classifier\n",
      "\n",
      "**Recall:**\n",
      "\n",
      "The image above shows a simple RNN model that for each time $1 \\leq t \\leq t_{max}$ gives the output vector $o_t$ based on inputs $s_{t-1}$ and $x_t$.\n",
      "\n",
      "In a many-to-one sequence logistic classifier, the final output is $o_{t_{max}}$. In the case of predicting labels for reviews the last output vector is used in the logistic regression. We call in lab session the vector $s_{t_{max}}$ as context vector.\n",
      "\n",
      "We could summarize the RNN model as a function:\n",
      "\n",
      "$$ f_{RNN}(U, V, W; s_0, x_1, x_2, ... x_{t_{max}}) = o_{t_{max}}  = P(y=1 | s_0, x_1, x_2, ..., x_{t_{max}})$$\n",
      "\n",
      "The set of parameters in RNN model to be optimized is $\\theta = \\{U, V, W\\}$.\n",
      "\n",
      "The RNN model is optmized following the binary cross-entropy criteria. For the example $i$:\n",
      "\n",
      "$$L_{i}= -[y_i log  (o_{t_{max}}) + (1-y_i) log (1-o_{t_{max}})]$$\n",
      "\n",
      "The optimization algorithm consists in find a good solution the equation above on the set of training samples:\n",
      "\n",
      "$$ arg_{\\theta} min \\frac{1}{N}\\sum_{i}^{N}L_{i}$$\n",
      "\n",
      "*Specific formulas of the Simple RNN model can be found on material of Deep Learning module*\n",
      "\n",
      "![RNN model](http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg)\n",
      "RNN model figure extracted from [source rnn](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, you should test others RNN architectures such as (LSTM and BiLSTM)\n",
      "\n",
      "An Embedding layer in Keras:\n",
      "\n",
      "Turns positive integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
      "\n",
      "In this last example, we transform the sequence of indexes 4 and 20 into real vectors respectively (0.25, 0.1) and (0.6, -0.2). Each index corresponds to a word in vocabulary. All word vectors are parameters of the model and they are optimized as parameters.\n",
      "\n",
      "[See this link for more information about](https://keras.io/layers/embeddings/)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2.1) Simple RNN model with Embedding Layer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we give you an example of simple RNN declaration."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.layers import SimpleRNN, Dense, Embedding, Activation\n",
      "from keras.models import Sequential\n",
      "\n",
      "embedding_dims = 300\n",
      "rnn_units = 50\n",
      "\n",
      "print('Build model...')\n",
      "model = Sequential()\n",
      "\n",
      "# max_words is the vocabulary size\n",
      "# embeddings_dim is the dimension of each word embeddings vector\n",
      "# maxlen is the maximum length of each sequence\n",
      "# Embedding layer definition\n",
      "model.add(Embedding(max_words, embedding_dims, input_length=maxlen))\n",
      "# Recurrent layer definition\n",
      "model.add(SimpleRNN(rnn_units, activation='tanh', return_sequences=False)) # Output of this layer is the context vector\n",
      "# Linear layer definition\n",
      "model.add(Dense(num_classes-1))\n",
      "# Non-linear function bounded (0 to 1)\n",
      "model.add(Activation('sigmoid'))\n",
      "\n",
      "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
      "# Show the model architecture\n",
      "print (model.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Build model...\n",
        "_________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "embedding_1 (Embedding)      (None, 500, 300)          26575200  \n",
        "_________________________________________________________________\n",
        "simple_rnn_1 (SimpleRNN)     (None, 50)                17550     \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 1)                 51        \n",
        "_________________________________________________________________\n",
        "activation_1 (Activation)    (None, 1)                 0         \n",
        "=================================================================\n",
        "Total params: 26,592,801\n",
        "Trainable params: 26,592,801\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train model\n",
      "batch_size=128\n",
      "num_epochs=5\n",
      "\n",
      "print('Now it takes time...')\n",
      "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=2)\n",
      "\n",
      "\n",
      "# Evaluate model\n",
      "test_loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
      "    \n",
      "print('Test loss: %1.4f' % test_loss)\n",
      "print('Test Accuracy: %1.4f' % acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Now it takes time...\n",
        "Train on 25000 samples, validate on 25000 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/5\n",
        " - 81s - loss: 0.5643 - acc: 0.7037 - val_loss: 0.5974 - val_acc: 0.6782\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/5\n",
        " - 48s - loss: 0.4767 - acc: 0.7757 - val_loss: 0.4965 - val_acc: 0.7782\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/5\n",
        " - 48s - loss: 0.2069 - acc: 0.9231 - val_loss: 0.5319 - val_acc: 0.7786\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/5\n",
        " - 51s - loss: 0.0554 - acc: 0.9854 - val_loss: 0.7102 - val_acc: 0.7276\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/5\n",
        " - 50s - loss: 0.0165 - acc: 0.9978 - val_loss: 0.6802 - val_acc: 0.7698\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  128/25000 [..............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  256/25000 [..............................] - ETA: 11s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  384/25000 [..............................] - ETA: 11s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  512/25000 [..............................] - ETA: 11s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  640/25000 [..............................] - ETA: 11s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  768/25000 [..............................] - ETA: 11s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  896/25000 [>.............................] - ETA: 11s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1152/25000 [>.............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1280/25000 [>.............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1408/25000 [>.............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1536/25000 [>.............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1664/25000 [>.............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1920/25000 [=>............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2048/25000 [=>............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2176/25000 [=>............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2304/25000 [=>............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2432/25000 [=>............................] - ETA: 10s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2560/25000 [==>...........................] - ETA: 9s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2688/25000 [==>...........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2816/25000 [==>...........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2944/25000 [==>...........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3072/25000 [==>...........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3200/25000 [==>...........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3328/25000 [==>...........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3456/25000 [===>..........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3584/25000 [===>..........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3712/25000 [===>..........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3840/25000 [===>..........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3968/25000 [===>..........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4224/25000 [====>.........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4352/25000 [====>.........................] - ETA: 9s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4608/25000 [====>.........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4736/25000 [====>.........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4864/25000 [====>.........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4992/25000 [====>.........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5248/25000 [=====>........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5376/25000 [=====>........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5504/25000 [=====>........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5632/25000 [=====>........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5760/25000 [=====>........................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5888/25000 [======>.......................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6144/25000 [======>.......................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6272/25000 [======>.......................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6400/25000 [======>.......................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6528/25000 [======>.......................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6656/25000 [======>.......................] - ETA: 8s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6912/25000 [=======>......................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7040/25000 [=======>......................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7168/25000 [=======>......................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7424/25000 [=======>......................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7552/25000 [========>.....................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7808/25000 [========>.....................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8064/25000 [========>.....................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8320/25000 [========>.....................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8448/25000 [=========>....................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8576/25000 [=========>....................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8832/25000 [=========>....................] - ETA: 7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9088/25000 [=========>....................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9216/25000 [==========>...................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9344/25000 [==========>...................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9600/25000 [==========>...................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9856/25000 [==========>...................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9984/25000 [==========>...................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10240/25000 [===========>..................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10368/25000 [===========>..................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10496/25000 [===========>..................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10624/25000 [===========>..................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10752/25000 [===========>..................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11008/25000 [============>.................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11136/25000 [============>.................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11264/25000 [============>.................] - ETA: 6s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11520/25000 [============>.................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11648/25000 [============>.................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11776/25000 [=============>................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12032/25000 [=============>................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12160/25000 [=============>................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12288/25000 [=============>................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12416/25000 [=============>................] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12544/25000 [==============>...............] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12672/25000 [==============>...............] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12800/25000 [==============>...............] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12928/25000 [==============>...............] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13184/25000 [==============>...............] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13312/25000 [==============>...............] - ETA: 5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13568/25000 [===============>..............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13696/25000 [===============>..............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13824/25000 [===============>..............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13952/25000 [===============>..............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14080/25000 [===============>..............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14208/25000 [================>.............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14464/25000 [================>.............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14720/25000 [================>.............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14976/25000 [================>.............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15104/25000 [=================>............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15232/25000 [=================>............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15488/25000 [=================>............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15616/25000 [=================>............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15744/25000 [=================>............] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15872/25000 [==================>...........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16128/25000 [==================>...........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16256/25000 [==================>...........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16384/25000 [==================>...........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16512/25000 [==================>...........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16768/25000 [===================>..........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16896/25000 [===================>..........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17152/25000 [===================>..........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17280/25000 [===================>..........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17536/25000 [====================>.........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17664/25000 [====================>.........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17792/25000 [====================>.........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17920/25000 [====================>.........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18048/25000 [====================>.........] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18176/25000 [====================>.........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18304/25000 [====================>.........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18432/25000 [=====================>........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18560/25000 [=====================>........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18688/25000 [=====================>........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18816/25000 [=====================>........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18944/25000 [=====================>........] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19200/25000 [======================>.......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19328/25000 [======================>.......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19456/25000 [======================>.......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19584/25000 [======================>.......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19712/25000 [======================>.......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19840/25000 [======================>.......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19968/25000 [======================>.......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20096/25000 [=======================>......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20352/25000 [=======================>......] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20480/25000 [=======================>......] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20736/25000 [=======================>......] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20864/25000 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20992/25000 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21120/25000 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21248/25000 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21376/25000 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21504/25000 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21632/25000 [========================>.....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21760/25000 [=========================>....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21888/25000 [=========================>....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22016/25000 [=========================>....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22272/25000 [=========================>....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22400/25000 [=========================>....] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22528/25000 [==========================>...] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22784/25000 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22912/25000 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23040/25000 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23168/25000 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23296/25000 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23424/25000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23552/25000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23680/25000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23808/25000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23936/25000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24192/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24320/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24576/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24704/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24832/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24960/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25000/25000 [==============================] - 11s 437us/step\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test loss: 0.6802\n",
        "Test Accuracy: 0.7698\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 2.1) What does the option *return_sequences=False* in *SimpleRNN* layer definition ? If this option is activated, what should be the *output shape* of Recurrent layer?\n",
      "\n",
      "Answer: \n",
      "It passes only the final decision to the dense layer and not the whole sequence of intermidiate decisions. If this option were to be activated, the output shape of Recurrent layer would be (500*50)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.2) LSTM/ BiLSTM model with Embedding Layer\n",
      "\n",
      "*Specific formulas of LSTM model can be found on material of Deep Learning module.*\n",
      "\n",
      "The LSTM model is more complex than the RNN model. It is pictured in the figure above:\n",
      "\n",
      "![LSTM model](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 2.2) What are the advantages (two minimum) in using LSTM instead of a simple RNN model ?\n",
      "\n",
      "Answer: LSTM are able to keep long term dependencies whereas a simple RNN tends to forget them\n",
      "\n",
      "Question 2.3) What is the bidirectional recurrent architecture ? What kind of operation is performed in context vectors of each direction ?\n",
      "\n",
      "Answer: https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks\n",
      "\n",
      "Question 2.4) Write your own LSTM and/or Bidirectional LSTM model and compare the results with simple RNN model. (use *CuDNNLSTM* layer instead of *LSTM* for faster results) \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.layers import CuDNNLSTM\n",
      "embedding_dims = 300\n",
      "rnn_units = 50\n",
      "\n",
      "print('Build model...')\n",
      "modelLSTM = Sequential()\n",
      "\n",
      "# max_words is the vocabulary size\n",
      "# embeddings_dim is the dimension of each word embeddings vector\n",
      "# maxlen is the maximum length of each sequence\n",
      "# Embedding layer definition\n",
      "modelLSTM.add(Embedding(max_words, embedding_dims, input_length=maxlen))\n",
      "# Recurrent layer definition\n",
      "modelLSTM.add(CuDNNLSTM(units=rnn_units))\n",
      "# Linear layer definition\n",
      "modelLSTM.add(Dense(num_classes-1))\n",
      "# Non-linear function bounded (0 to 1)\n",
      "modelLSTM.add(Activation('sigmoid'))\n",
      "\n",
      "modelLSTM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
      "# Show the model architecture\n",
      "print (model.summary())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Build model...\n",
        "_________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "embedding_4 (Embedding)      (None, 500, 300)          26575200  \n",
        "_________________________________________________________________\n",
        "cu_dnnlstm_1 (CuDNNLSTM)     (None, 50)                70400     \n",
        "_________________________________________________________________\n",
        "dense_4 (Dense)              (None, 1)                 51        \n",
        "_________________________________________________________________\n",
        "activation_4 (Activation)    (None, 1)                 0         \n",
        "=================================================================\n",
        "Total params: 26,645,651\n",
        "Trainable params: 26,645,651\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train model\n",
      "batch_size=128\n",
      "num_epochs=5\n",
      "\n",
      "print('Now it takes time...')\n",
      "modelLSTM.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_data=(X_test, y_test), verbose=2)\n",
      "\n",
      "\n",
      "# Evaluate model\n",
      "test_loss, acc = modelLSTM.evaluate(X_test, y_test, batch_size=batch_size)\n",
      "    \n",
      "print('Test loss: %1.4f' % test_loss)\n",
      "print('Test Accuracy: %1.4f' % acc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Now it takes time...\n",
        "Train on 25000 samples, validate on 25000 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/5\n",
        " - 19s - loss: 0.4921 - acc: 0.7608 - val_loss: 0.3613 - val_acc: 0.8464\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/5\n",
        " - 17s - loss: 0.2245 - acc: 0.9140 - val_loss: 0.3284 - val_acc: 0.8600\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/5\n",
        " - 17s - loss: 0.1070 - acc: 0.9647 - val_loss: 0.3784 - val_acc: 0.8450\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/5\n",
        " - 17s - loss: 0.0745 - acc: 0.9752 - val_loss: 0.4564 - val_acc: 0.8551\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/5\n",
        " - 17s - loss: 0.0475 - acc: 0.9858 - val_loss: 0.5081 - val_acc: 0.8464\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  128/25000 [..............................] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  512/25000 [..............................] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  896/25000 [>.............................] - ETA: 4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1280/25000 [>.............................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 1664/25000 [>.............................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2048/25000 [=>............................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2432/25000 [=>............................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 2816/25000 [==>...........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3200/25000 [==>...........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3584/25000 [===>..........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 3968/25000 [===>..........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4352/25000 [====>.........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 4736/25000 [====>.........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5120/25000 [=====>........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 5632/25000 [=====>........................] - ETA: 3s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6016/25000 [======>.......................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6400/25000 [======>.......................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 6784/25000 [=======>......................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7168/25000 [=======>......................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 7552/25000 [========>.....................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8064/25000 [========>.....................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8576/25000 [=========>....................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 8960/25000 [=========>....................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9344/25000 [==========>...................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " 9728/25000 [==========>...................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10112/25000 [===========>..................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10496/25000 [===========>..................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10880/25000 [============>.................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11264/25000 [============>.................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11648/25000 [============>.................] - ETA: 2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12032/25000 [=============>................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12416/25000 [=============>................] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12800/25000 [==============>...............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13184/25000 [==============>...............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13568/25000 [===============>..............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13952/25000 [===============>..............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14336/25000 [================>.............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14720/25000 [================>.............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15104/25000 [=================>............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15616/25000 [=================>............] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16000/25000 [==================>...........] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16384/25000 [==================>...........] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16768/25000 [===================>..........] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17280/25000 [===================>..........] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17664/25000 [====================>.........] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18048/25000 [====================>.........] - ETA: 1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18432/25000 [=====================>........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18816/25000 [=====================>........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19200/25000 [======================>.......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19584/25000 [======================>.......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20096/25000 [=======================>......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20480/25000 [=======================>......] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20864/25000 [========================>.....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21248/25000 [========================>.....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "21632/25000 [========================>.....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22016/25000 [=========================>....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22400/25000 [=========================>....] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22784/25000 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23168/25000 [==========================>...] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23552/25000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23936/25000 [===========================>..] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24320/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24704/25000 [============================>.] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25000/25000 [==============================] - 4s 150us/step\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test loss: 0.5081\n",
        "Test Accuracy: 0.8464\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 2.4) What do you propose in order to improve the results ? (Hint: verify the results of previous models and think about overfitting and underfitting)\n",
      "\n",
      "For instance you can use regularization methods:\n",
      "- (Hint: use the regularization method just after the *Embedding* layer)\n",
      "- Describe the regurization method used\n",
      "- Compare the results\n",
      "\n",
      "Please implement and build our own model here...\n",
      "\n",
      "Answer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CELL TO COMPLETE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 3) Analysis of results and data visualization \n",
      "### 3.1 ) t-SNE 2D Visualization of context vectors (test data)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "t-distributed Stochastic Neighbor Embedding (t-SNE)[1] is a non-supervised technique of visualization of high-dimensional data based on KL divergence probabilities approximation to construct a manifold.\n",
      "\n",
      "[t-SNE sklearn manifold](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
      "\n",
      "[1] Maaten, Laurens van der, and Geoffrey Hinton. \"Visualizing data using t-SNE.\" Journal of machine learning research 9, no. Nov (2008): 2579-2605.\n",
      "\n",
      "In this example, we will use this technique to visualize context vectors of each document (review) in a 2D space. The original euclidian distance between high dimensional context vectors is mostly preserved. Therefore, we can have an idea of the projection of context vectors in a 2D space. \n",
      "\n",
      "We will plot this representation using a scatter plot (please use a sub-sampling of test data for visualization)\n",
      "\n",
      "[scatter plot matplotlib](https://matplotlib.org/gallery/shapes_and_collections/scatter.html)\n",
      "\n",
      "*plt.scatter(proj_x, proj_y, c=y_test, cmap='rainbow')*\n",
      "\n",
      "The colors of the points will represent the real label (positive or negative review) of the predicted context vector.\n",
      "\n",
      "Apply this method in context vectors (for training and testing data) to perform a visual analysis\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.manifold import TSNE\n",
      "import math\n",
      "from keras import backend as K\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Function that takes the output of a specific layer of the model\n",
      "def get_activations(model, id_layer, X_batch): # PAY ATTENTION TO THE ID_LAYER !!!!\n",
      "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[id_layer].output])\n",
      "    activations = get_activations([X_batch,0])\n",
      "    return activations\n",
      "\n",
      "#  Function that takes the output of a rnn layer of the model (use batchs)\n",
      "def get_context_vectors(model, X, id_rnn_layer = 1):\n",
      "    batch_size_test = 1024\n",
      "    h_context = get_activations(model, id_rnn_layer, X[0,:].reshape(1,-1))[0]\n",
      "    divs = math.floor(X.shape[0]/batch_size_test)\n",
      "    h_ = np.zeros((X.shape[0], rnn_units))\n",
      "    for i in range(int(divs)):\n",
      "        h_context = get_activations(model, id_rnn_layer, X_test[i*batch_size_test:(i+1)*batch_size_test,:].reshape(batch_size_test,-1))[0]\n",
      "        h_[i*batch_size_test:(i+1)*batch_size_test,:] = h_context.reshape(-1, rnn_units)\n",
      "    if X.shape[0] > divs*batch_size_test:\n",
      "        first_id = int(divs*batch_size_test)\n",
      "        h_context = get_activations(model,  id_rnn_layer, X[first_id :,:])[0]\n",
      "        h_[first_id :,:] = h_context.reshape(-1, rnn_units)\n",
      "    h_ = np.asarray(h_).reshape(-1, rnn_units)\n",
      "    return h_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 3.1) Get context vectors (for training and test data) and complete the tsne transformation of these vectors and then plot using scatter function of matplotlib with a colorbar (Hint: use *get_context_vectors* function and specify correctly the id of the layer). \n",
      "What means the obtained results ?\n",
      "\n",
      "Answer:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Then plot using scatter function of matplotlib\n",
      "n_subsamples = 1000\n",
      "X=get_context_vectors(model,X_train[:n_subsamples],id_rnn_layer=1)\n",
      "X_embedded=TSNE(n_components=2).fit_transform(X)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proj_x,proj_y=[x[0] for x in X_embedded],[y[1] for y in X_embedded]\n",
      "plt.scatter(proj_x,proj_y)#,c=y_test, cmap='rainbow')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "<matplotlib.collections.PathCollection at 0x7f6b19325990>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztvX+QXcd1HvhdzLx336/5hQ1ESRSJAfGDBAiAAFRiVGXX\nLm2LXCm1jlWyGVpyypYJ06S0EJkoXnPIFAlLNL2mUUxKY62ERcws5BRATCopWWFV7JFUevxjUqV9\njCiKdAaSZcvQD9vhQ2yvK3JYEiWf/aNvz+3bfbpv933vzXuD6a8KBWDm3Xf79r339OlzvvOdhIgQ\nEREREXHtY8e4BxARERERsTmIBj8iIiJimyAa/IiIiIhtgmjwIyIiIrYJosGPiIiI2CaIBj8iIiJi\nm2Bgg58kyVuSJPlCkiT/JUmSV5IkeTD7+UKSJJ9NkuRrSZKsJkkyN/hwIyIiIiKqIhmUh58kyRsB\nvJGIXkqSpAPgSwB+CsAvAvhLIvqtJEkeBrBAREsDjzgiIiIiohIG9vCJ6L8S0UvZv78L4DKAt0AY\n/U9lH/sUgHcPeq6IiIiIiOoY2MMvfFmSLAJ4HsBhAN8mogXld39FRDuHdrKIiIiIiCAMLWmbhXP+\nHYCHMk9fX0mihkNERETEGDE9jC9JkmQawtj/GyL6TPbjV5MkuY6IXs3i/H3LsXEhiIiIiKgAIkpC\nPj8sD/9fA1gnoo8pP/sPAN6f/fsXAHxGP0iCiCb+z+nTp8c+hjjOOM6tPM6tMMatNM4qGNjDT5Lk\nRwD8HIBXkiT5MkTo5lEATwH4t0mS3AvgmwD+0aDnioiIiIiojoENPhH9JwBTll+/Y9Dvj4iIiIgY\nDmKlrSfuuOOOcQ/BC3Gcw0Uc5/CwFcYIbJ1xVsFQaZmVBpAkNO4xRERERGw1JEkCGlPSNiIiIiJi\nwhENfkRERMQ2QTT4EREREdsE0eBHREREbBNEgx8RERGxTRANfkRERMQ2QTT4EREREdsE0eBHRERE\nbBNEgx8RERGxTRANfkRERMQ2QTT4EREREdsE0eBHREREbBNEgx8RERGxTRANfkRERMQ2QTT4ERER\nEdsE0eBHDIzLly/jU5/6FC5fvjzWcVy9ehUvvPACrl69OtZxRERMKqLBjxgIH/rQP8GhQ2/F+9//\nGzh06K340IceGss4nn12Bbt334I773wAu3ffgmefXRnLOCIiJhlD6XiVJMkzAP43AK8S0dHsZ6cB\n3Aegn33sUSL6A+bY2PFqi+Ly5cs4dOitAL4I4CiAlwG8HevrX8LBgwc3bRxXr17F7t234LXXuhvj\naDZ/DN/85lexa9cu7++5fPkyer0ebr/99k0df0REFYyz49X/A+B/ZX7+L4joRPbHMPYRWxu9Xg/A\nDRBGFtnfb8l+zsMn7BIamrly5Qrq9cXCOGq13bhy5YrX8cDk7FQiIkaJoRh8IloD8NfMr4JWn4it\nhdtvvx3AtyE8e2R/fyf7uQmfsEuV0Mzi4iK+//0rhXG8/vo3sbi46HUdly9fxsc/fg5ip/I1AF/E\nxz/+r4JyEsPOH8R8RMRIQERD+QNgN4CXlf+fBvANAC8B+B0Ac5bjKGLr4tSpBwloErCfgCadOvUg\n+7l+v0/N5k4CvkIAEfAVajZ3Ur/fD/qMDRcvXqJmcyfNzh6nZnMnXbx4yfsazp8/T8CB7Jzyz346\nf/681/Hy3HNzJ4LPvRnfF3FtIrOdQXZ6KDF8AEiSZDeA5yiP4e8C8N+IiJIk+XUAbyKik8xxdPr0\n6Y3/33HHHbjjjjuGMqaIzYFP7PuFF17AnXc+gL/5my9t/Gx29gQ+//n/G29729sAAJ/97Gfxnvf8\nKv72b1+yfsaFq1ev4sqVK1hcXAyO3VfNRQwrfzCq74u4dvD888/j+eef3/j/Rz7ykeAY/sg8/IDf\njWDti5g0lHnvFy9eokZjnoAW+5l+v0+9Xs/L268C352Kjl6vR3NzJwq7g9nZ49Tr9SqNY9jfF3Ht\nAhU8/GEa/EUAryj/f6Py738K4KLluNHNSMREwRZ2KS4GlwhYIGDvxmf0EMfZs+dGYvzX19fp/Pnz\ntL6+7n3MIGGozfi+iGsXYzP4AC4C+HMA3wPwLQC/COB3IfbGLwH4PQDXWY4d8bRETBI4T930avvU\nbh+g1dVVxgA+RUCTZmbCY/WjQtXdgQ2D5CMitg+qGPyhxfCrIvLwI1xx6ytXriix/6sAbgEwOfHt\nfOz/HkAbwN+i2fzpgcdUNR8RsX1QhYc/ParBRET4YteuXXjmmU/g5MkfQ622G6+//k0888wnNgxd\nTrn8HnLe/1UA38PU1Jtx5coVL6OoGlEAQzGosgbgtdfu2PiZrAHQvzfk/Lt27RqaoY+LR8QGQrcE\nw/6DGNLZMhh14tT2/TLE0ekczkInTxGwk4DbCGjS2bPnvL9jbu4E1WozVK/PDYX2WAw59Qm4QI3G\n/KadvwwyGd5u30yNxnwMD11DwDiTtlX/RIO/NTBubrg05GfOPJ0ZfTOpaRujaZQXhpoUvXjxEtVq\nMxnDaB/V63OF+Rn1+W3o9/vZuBYIOEHAAtVqncrnqpLUjhgdosHfphj1izhJzJFer0czM8cN2uLq\n6qp1jMWkcC8zfsXjB6E9ls1P8fyrBNycGf7hnN+G1dVVg+YKtGh1dTX4u06deihbaA8MJTEdMTiq\nGPyolrnFsRkaMJxWzfT0jV5aNcOWCFhcXMQPfvBN6DIKAKx6OkXphUUAf2oc7yvDwF1PcX6KuQU5\nZnH+3wLwXgA/BHAzgJXg84fjzShqHb0p+BuGIT0RMSEIXSGG/QfRw6+M9fV1I7wBNIfu6XMerB47\n5zCqMBBHW/Qp7JLH1GodqtfngmmP5SEje27h7NlzzL1qjTSu3u/3qV6fK5yzXp8L3pkNKj0RMRog\nhnS2FzbzRcwN1tHMqD3lDOuMOgzEJWfL+OvqMaEJaNv1yFqBokE3k7dcKKrdPlopvGK7fg5yTtrt\no9RozNMTTzwZfA82y7GICEM0+NsMm/kiCoN1JIuB90tjz71ej5rNIwUD12wedsaqh8ECGhWTiJM8\nAPZSu30zNZs76YknnswM+qVsQTxBQIueeOLJjXGFLoD6tcj/nz17Lmjn1O/36YknnhxotzXs4rKI\nwREN/jbEqF9EaWTW19eDDFZxMRIeL9CwLkbjZgFJ2BYMPqy1kF3bV6jRmM+0gOwMnJAKWn0+7r77\nZ6nZ3JktKpKa6r9wDGO3FVk6k4Vo8LcpqmrAlHnCutE5derBjNN9oDT2LDz8PQTkdEXV49XHYjNI\no+b+qyjjrKvhEXFNlza8/dnZ43T//R/IrjPfBczMHCvsanyux5yPLrOT2+m10yKKgmzXKqLBj/CC\ny5t2efT1+lxmEG8r9VD7/X7m8c6XepY2g7S09Cil6SzNzBwZudfvy1nv9/u0urqaXVvxurg580lu\n6zDno0dmruZo9vPN8/AjJgvR4EeUwvXyqwtBms4aMXhgbxaa8TMaTzzxpOHxcp4lN6ZabZaABgnG\ni1+SeJCdQChn3RaeCU1u266l3MNvUqdz2HshjIJs1x6iwY8ohS35ahYucUamRSEFQyGepW6Qpqba\nRgij0+GTvnmopXznYYMw+MXFCdjrZNHYlD9Dkts2yGsSi+wCAQ+SKhtdRSJ6M8Njm3mu7Ypo8CNK\nkXugRc95dXXVCKs0GouUpvMbRrhW6wSHBUI8S2kkVldXDQojcJTSdJYNsQzKNZdhGrGrGIyznoey\nLpBM6FYNn0h2TaMh7kFVWqX6fZthhCclAX+tIxr8axDDfEldBVQ2b3x9fX3j/FXDAsPgvNti4S7P\nPDQxXat1qFabpXb7qPP6XN978eKlbAESSeparTOwwRvGM7BZRjjmCzYP0eBfIyjjW1c1AFxytN0+\nTOfPn/c26FXPHVr0JMcyM3OM0nTemvi0xd4ffviRUgPHGadGY35jsXCNi/ve9fV1StPyJDU3J6PE\nMIyw71gjI2jzEA3+NYDc0PF869CiGxXmi292jxqFEVKNZL0+R7Vax2v8vhRGEWpaIOA4AQs0Pd32\nMnD8Amivfi1LeKfpLOlsGpux0xeOQUI1ZRjUCIfsDqKHv3mIBn+Lgw9l5HzrTudwkAfJwdSWH+2L\nWVawpJ7TZeDLwihqfcATTzzpZeD4sdn1bWyGM094d7P75Z5T13mH3a9X5ieqGuEqBvzs2XOUpvPU\nao2eTrudEQ3+Fgdfvp/zrQUn3ZQGDt0u9/t9On/+/MDf5eOB89d0PLum/JwuLzLf9RyhNJ01wjvS\nqMlQTBV2UM6GuRRkqM2Et5RW2E9p6r9wiDm5kO24hmMopeGdmakuGBe6O8hzGHsISGl6uh0N/ogw\nNoMP4BkArwJ4WfnZAoDPQuiprgKYsxw70knZSrAlKyXfWoZzhhGLDZVK0KEaaBd7xMfDd40lP55X\norQtFCEJ5tXVVWq3TY361dXVUoG2s2fPWSitKaXprHfuIN/J8QVVoaE20SgmzcYizlGWn+AQsnja\n7jXXASzSNgfHOA3+jwI4phn8pwD8avbvhwH8puXYUc7JlgNnUNQXY5ACGtXjazaFVEJV1k3+Yl/K\nDPg+63eoY5YxfPWcLi8y57UXDUmazpcuWr6SE3zh14x1x8El1SXDx2enoM5J/vlzmYc/Tzp/X79v\nZfcpp94eyOZNSEDoMg++8H3mer0etdu3GTuXdvtA4byRtjkcjDWkA2C3ZvC/CuC67N9vBPBVy3Ej\nnJKtiTLvp4p3xOmx67RLX+QGum8YYpf3Z2PpuLzIfr9P09PtzLPPDcnMzDE6f/68daEINSqqUWs0\n5g1uv35d3Jjr9Q7V6zcVdgouhVDJsxfX18qM/2xhsXC1dLR9p57nEfeoS2lqetq+8E2gl3n4Mak7\nPEyawf8r7fd/ZTluZBMSIdDv96le7xBQlErw8fi4Fz1/aS/QsNoF2rzIfr9PU1Mt62LFGY+q4Sp5\nrVwRmn5dPMPnFmOcZXLVZQlcwfwpLnat1hErk4jT3RdKqmmwpk8V5DH8vcTVIUTa5vAw6Qb/Ly3H\n0enTpzf+dLvdUc3PtoXQtGmSzld3eXzS+2w05q2JVFFRWvzOMg/ftaPgFhcx9hYBi9k13Eqq6ia3\nUAxqVHy8UO4zaTpLabqYedTHCJinNL2BPa9rcZHUUFs4y8UksuWBzpx52uvauTH61k6ox6lJ9NC5\njeDR7XYLtnLSDP5lLaRz2XLcCKdocjGeoptLBEjvy67imMeX95ErHi0XBTUUwiVv5fc1mzcR0KRm\n84iXTIBpHLoEzFCazhYWjpAQkS984tYqxTVNZ+nMmaez8z5GIjRzKzvPesLbFj4yE9ZHs0XvnPOa\nyorWfJ69qrUTPohCbsPBuA3+IoBXlP8/BeDh7N8xaatgM5NWRW/3IRIKlDcQ0GCbpbgYJDYvWd0N\n6Fry+fd1FU+1PNFrjl3+2Ut3331P6fyp2vW2pGvZYmPzUlXoCdV7772PXDF3PkHcsRpAeR2t1iES\nrJtzXrsW2zX6PHs+zKpBHZXI0hkc42TpXATw5wC+B+BbAH4xo2V+PqNlfhbAvOXYEU/LZGGzt7T5\n+T5tGCIuvsxRFAVH/JNUr3doZWWF3abbtORzo93LfheW6NXnqtFYYLXoOcPGLUA+Bs93QebDOvPU\nbh8uLFKqYXYVb7lCXTYN/lFQLH1rJyLGi1h4NQEo81yqxpd9vVKbV1ertUkk79SXuNjw3BbKEZ5l\nk2yCYLmeTTczCl2SWvKmh++X6NWpj9L7FSEkd69cm2HzSeaGLMjcvRRhlFnr8WWMJNc9HjQUYiZ0\n+9RuHzASwJvh4UcMjmjwx4yq2+WyF6is0tTn3Gtra04P38YWSdNZmp6eMV5+lWonDP6bKG/evZOA\n6zYMiRxbo7FIIqTkTvTq16LWIojrKBYUAU1aW1vb+IxtUXXROCV8FmQ1Ac3dS32R0u8FZ7hDdhVV\nQyFFaq47rFZWO+GLGLoZHaLBHyNCDHmoRnwxcVesNDXPLRqGc9WNrobnNiGx5eXl0mKaYsNyczGR\nY5RGUk30cvF12zwKgbL5jfEL5s5Omp5+A6XpfGGBGJWHrxtmW/FamaHTGTCjDvMVnyM/dlVVlo5E\nLLAaLaLBHyNCQzW+L5Cr0lQem59b6ricIFvDcFv1aUgYBFigen124zt6vV5pmMX3+m3fxQmACcN1\n3lhsisnT4uIWwr7hjLhtjgbxYkNVO0PmU6KYm1klnds/7Lh8pF+OHtHgjxGjesD7/T5bfKMWTfX7\nssvSwkDntxk6vZgGqFOzuWfjM6HX7jJOtt3CysoKk0jcT7Va21gg8jh6l2ROQR2Pj+SCuiMpCxUN\nuqjbwmk2rr163OrqKi0tPWqtlyDicjPnBn5WyjCpBVbXUogpGvwxY1T8YpssgvrQcg3DQ71EIvsL\n0e/3aWVlJavY7RrjyOmJx5zXXrbNFx7+nmyncpwAEfvnPPw0nae1tTX252JXZBqbkDCDzpdfWnqU\nPRe3cFSVdtC1eGxtFvNFeF+2CLeJq5ewLSbT022neuaghjHECdgsI3ythZiiwZ8AjOrhLTOoVb3E\nENi8NhmTdyWVbWO0x9BN79y1A1F/PkgMnx9rnuCcnm5TrTZLjYYoqlJ3OiHXyWFlZYWAt1CREms2\nUrezaITwWhkNVDoCtmf17NlzVK93qNXaO9DzExI+i60XwxEN/jUOX9qer2JjlfPrL02jMe98kdQx\n+27zXYbCtQNRQzBnz54rNEWxSS5IETY7F92sGxBMoyJTSI3l+2jxcLC1a9QNvk2VUqhjXij18F3P\nQ76bzHcOsqbC9kxUFfrzJRuon9f7Hvg6V5MaYhoE0eBHWLXdqz7Y+kulG2NXdymOXjnMbb5tbEKu\neCZrSH6bM9dgaziSf9asGxCGtRgyajT2FJhCou1imDe5vr5OU1NtUts1csbW7uE3WY/cN9Qo8kW6\n0qb4Xi40OKh3biMbPPDAB4xr1kNYO3Y0qV6f8z539PCjwb8mMcwH2/ZC63Q9oQOfn69en6vMUXdd\nl824m4tJn7ik5Nmz5zJDLKWIzZ7B6jzZBOJE6ETX+Gkac9BozHtfZ643tIeABtVqe5zhFD2RPjXV\npKWlRyt74kTCALdaR5mdw/VeYaXQ58xGNtBDkbaFmssluXCtafhEg78FURaiGMRQD/Jg+77QIgRQ\nN7zSYlijT0CPOp3DhfCO77X57BSKiVop45AbrmIFbJ+Aj5Jow2fuTPR5EDpBC1QMlckG8McyPft9\nxne55BLcc/1pAmpUq7WdAnP9fp+Wlh6len3WuzlK2Di+kt3PGUfIyz1/ZeDIBrLdo3ze+BDWfpJS\nDyHnjiydaPCHBt8OSxI2D5r7eeiDWkZ9LBsn9yJyFac5ZbSfvYB9mpk5prBq7AVjvtdhGnezt69p\n0BdIXxDa7YMbYxR//KSd5TikQJze3lCctzrNsRiGy3viCi/2jVZDPoowhb5z0GU0+HP7xd9tjo25\nyBTF+tbX15lQE+/hX0sGvQzR4I8Rp049RHlbuSarRKnC9rJyoRAZHhgGk8FnnLattm5MyorCqnTZ\n0l9Y05PsU6OxOxNrs4eL9Kbd9977y9lYbsvG+5RTpdJ13/jxSUN9nGxFbxyKHPl5Aoqxf9mtijPk\no0pE6slR19jFfWgRsI9qNb6Hb1ms30U2kPdUhLqaGwvRjh0Ng1Z6rdEuyxAN/pjgIy2gI0TvRTzk\nFwrG7bnnnqPHH3+c1tbWhj5OmxHTk2n5olXUa5de/OrqKrVaB0hv+Zems9amKtzOpkiPlH1jZQHY\nYWd+waZ5I8c5qEfo8nR9GCzmuFpkKpX2rOGmYXr4oeFFW/6Gf0bcY7TtoIrHdguKrfq9LjvPteb9\nR4M/Jpw/fz7zmFUjXVSi1BHi4etGIEnmSZUNuOuudw11nKYRO0VAg40TSyMtm4BIY29X3rRvxW0v\nrCt5Wq93SkNoNjrmIJ6w6gVziWiX4J00PBx9U1/cXR6+Os8+DByXsbM1Snd5zYJGqsffi3UDg1Qn\nhxxb9tlr0fuPBn9MqOLhE7mlDNSfFyl+pnaMVIscdJzqy6YacluVr+pBq8bE5rnW67PZ1tx8Kcte\nWJETKOrMSxG3suQoFwMexBPWKYK1Wqeg6GnufPL8hW54dPqmDN+l6SESNMvFUgPF7Wp0tpHL2LlC\nby6v2aduYJBdSMixrs+OItcxCYgGf4xwKVG64LONVheAqakGmbr2++jxxx+vNM67776ncA49nHL+\n/HkjQapW13JGhDPerdYRevLJJ7UmHt2NdoVlL6WNQTI11cqSuCaXnkinOzaNEFDovbGNQ01Y2nIb\n9foc1etmCESnb9oW0jKUh8T4ebVpNZXJSYuQTofK6gYGYY2FHGv77LVYdEUUDf5YoBqFUJZOlfM8\n99xzlT18ifX1dbr//g9Qms5Su30zpemsR1/V/Hc+1bVczHxm5siGtnqjIQ1wbqjLXm6dQZIksjFL\nnohVxyE8eymiRgR8mmq1ttdc2bxiW5WrKhdtM6Ji3Dcahqdsh+ITe7YZdlvYSCaVXYl3HykKGW5T\nK5qrXoPr2lw7mLLzRA8/GvyhII/THmebRY8Kd931LsrL3/1j+BLCM1NbEs6QjYIpk2mqIXZV10rk\nc3OM9AKnRmPB8HT1MJHrhV5dXaWVlRWGqrdzg+t/8aLUzj+QGbMHs78PUJqWq1CGhAd0D5+ID5MI\nFo4ZWnKxYVzhGJ94Ny8rvVBILLsS7z4edtUdSegiMEgc/loruiKKBn9TYfNiN8vor62tBbN0JMzY\na9cwTipLQqpFyiIgV8JZj+WLkFBRhqDdPprxzu0Lhg1qwrPR0GP6hyhNZ2ltbU3z7N2Vmbrh8UkA\nlnHV+/0+LS09Qmk6T63WkWy+zxHwJEmefa02S7Vax2rAyhLZqvE7ffojWRvLTxv35IEHPpCd/3h2\n7kvU6Rze0BCyJd71ObfFzqV2UYgxDjXew/DSI0tnEww+gCsAvgLgywB6zO9HNiGjhNgKF2PbwFFK\n09mhPlBVH1LXcTy74jpKUxclrviC6eqdsvOT3pZQGF/Tq63SkFs1EqLytW4suO97389pnv0lknkO\nrjIzNO6terM2rnpxnEJWWVTjyh3VHE1NNdg5kIumDA9y+RPTa38fqXmZ6eldhXsiFtwGCfZPn/Iq\nYTNvEPKcqTvc4i4uz83Yns1Q480twmpoyoZrzcirmFSD/w0AC47fj2g6RgsRp7WHFIaBqlvYsuPW\n19czA5R7vFL/xocSp1MOz5x5WnuBhUERHniTarU3ZP+/ZcODtG2xbTFYPjTRIhEiEZ5rmu42GohL\nWiPn4bti1Nz4fO6HLeeh89Wnp9uGMZcCbKKhS5PS9Ebidl7FuDzPvHruuefYe9Ju21lXIeB3uDtJ\n7GLcoTOfKm6/85mhNBXXIhVTxaQa/D8F8D85fj+i6Rg98jjtUeKShoOg6ha2jIKYs1aEUanXbyyE\na8rOzxnJoo4NJye8k4APE9CkTifX89eNu9w1dDrHNnIicrwiBGRyvoFPktTN5xqfAPspTWfZ3rNl\noRs9WWga8gXjfnDf2W4fMBK9InxSZCyZhnsnAY+R1OzhdyB8bcXjjz9ujKPTOUyPP/44u2soM7b6\nIsx73IeIy1Hoz1XV7mxioSiGpmxjv1YTtSom1eB/A8B/BvACgPuY349sQjYDwkjNUqczGN1PRxUq\nmUhUzhoGQE3A6i+BaObByzZwXq6tiCn3rHtkslOOkaiQtb98fJKzqUgomPo4OqXRJqrG1RkQcSwe\nu1GwhRTuvvse4976sprUgq00nSW9VaOsslXj7fq9abdvYeeN6wRWtquxPVOcl8x73CnplGH9ma0q\nRSF3eWk6R3loKux+cVpQWzncM6kG/03Z37sAvATgR7Xf0+nTpzf+dLvdUc3PyBDy4LgqMPXvDHkx\n8893Sfew5XE2o6XLNugeWVlRlWq8uEIt4fXdan357DTGW0l0gJL/v0RAi9rto+wuQTKKbLx2zmDK\nnQ5wHZWJhYm8QTGkADSMWLUrHKQuTiqzha+wdlfZSiOY01NFDH/HjoY1LGUbn+27XbkW9XsajXl6\n8MGHSgvcis9Pueha8V7dRCJvI+St6/U5Jw3ULwe1dVg73W63YCsn0uAXTgacBvBh7Wcjmp7JQ/4Q\nPpYZwSIFTkdI2XyRDZMrLqpxVN4rK8o22DRbVIOpUi5VOqrO2BCVsU1K0xuMRUB9+WxccDFHxeMa\njfnSRGmzuXMjROWblAXmSMTD7QuryXY5R8ANtLy8zN4TLhehzo/anEW9BjlvPlW2vV6PGo2DBKwQ\nsEzAOjWbhwuLaYg+jjoOEYZqUZ745r1ktQhPF63jxh5CkeQdmbCFQj+PT4/orYCJM/gAWgA62b/b\nAP4TgLu0z4xuRiYM4uXcbTxsUl2SQ9nuIZQp4ZZt4AtruC29DGXpFa4qi0X929X4JH+pi1xw4Ke9\nPDq/fENuJEQCWA+fHCbJ4rGFzoQ0hWS7PJ0tEnup0Vjw9hD7/b5R5KYKjunzV2aEzpx5OpsruWCK\n5GzV4j9bctQWQrGFsGxtCEOvL9+Vmj0OfKi83PltlcVbrfJ2Eg3+niyM82UArwBYYj4zuhmZMAiD\nkRoPW6dzW6WHrej99Egm/sryCepL4PK28gRbMWbq6mYlqi5vZqsufbzKRuMWAlKq19+sLIxuj84W\nr82lAYot9B588CHi4t5lHj6RlKaoV/YQBSV2D+W6/ERco3IfiJaIM8Z1pOkN3s+Tfk9sYb92+wD7\nTPmwuaSzoFN3fZ4Pn1BlCISC617ju1xO16Ri4gy+1wCuMYPvMmr59tv+sIXkA3q9XhbXlMZsJ9Xr\nN9Djjz8e5OHZzpmzIk6QyorgNFZmZo7R1FSLcq45r6viMw4XB50LN3GUTbkwcYyQNJ2lNF2kPGm4\nk4Cd1Grd5Iz7y/PV6zOVPcSHH36EdDkIrlG5z85OeKq6rtJeqtf95j2kBsFWDey3u1IX1S5rsF0U\nytwZWKRB9JDk9wi2V5vEDs0eVp30pG40+GNGGe/XFrrQy9h9ecOm+qXYzqvURxvKHuZ+39Q6l7xn\nvknLLJW0SYEBAAAgAElEQVQpJ4bAJ2mtzpctdsxxvnNKZJdE5atQvtSpoDZhOFfTl9BrEoVSba8w\nmvk9ptcLtGhp6dGB5jdUhsCXzWVrS+hzr0NDQfo8NhrzRihN0JI7rLHfChz+aPDHCF9Wja2Mvex4\nzkALD9/Of7dteX0eZpvWuTQm+nWIMIlbG901d1ycl4v7qy++K3Zs3pcuybCXGn7i2hzqzBQ9Ju1a\ntF3wqRb1eY6K36O2RJzz3lWF1CD4gLuHvh5+1SrasvEUz3/BeD7b7aPs8+n7Lo8b0eCPESG8eZvx\n9o2F8qwbk/8+SJckH61zldrWaMzT9HQxnqx3P+Jgxnkf2khCp+k8nTnztLEln5s7kVWkljchJ7K3\ndRS9ZItzZur8SCpozqhxac+4DGW4Meevy/yeLgEppSnfYpDDZhg13fPnit9sYymroi2DOY/+PYyr\n1MCMA9HgjxGDvkAhsVAu9ulqVKLC9TCrxkqEdOxa59x4hezxQoEnH3bNXeMa1FaEOuNGMGa6zut1\n3Rfb73IP3yz2kvFsLrTAVQrrKAuXhO4UBQd+gR544APOvI3Mdag7oJDQjSr9HeL9c54/p0EUUkXr\nA9vz6XO90cOPBt8LobFPn+PLDLSUCra12tNhe5g5tcOLF+1a57ZxcdruNgNhfkePTJkAIUiX68cU\nGTdTU43C+HxYJ1zrO65Iqt0+QFyYqt2+2ZhfW6Uw1zfXJyGrjkntpqXfS1lo5grPXbxYbDau0lul\nIV9bW7OOSd8h7djRMETyfI2ha7fKMcIGMbLcvfVdrAZ9lzcD0eBPAAbN7OtNVFwGmnuJdS+dGwtn\nUFxesM3Y+HhBropGPw9f7F7yqk+92rVJrdathZBBSMcn2z2TiykXatANUr9vqxQ+QlNTLauBK0ua\nq3kMmx6+Pn967UVuSM2dSl4gdxPpzWjU59FOYTVVN10ouxejMLKDvI+hC/VmIxr8IcD28ocyBKrA\n5v1wBrpMgMqH6aGGcarELMteUOH1qrK8dqaN/I57772PbIJ0HONGfK6nGKJuYT7W19eNBi4hhiT3\n9o+Sreo0pFKY203pwnXqPXIZSD55W1Sp7PV6WU6ieH9brSOKjpD9HLbG96Kqlw9BumjJW1HfRj57\nrvdpHIgGf0BwRjIvdz+SeUF7gm+4z0Nc9nLrBpp7idvto1aam02SwOfcVa6t3+9nvPwij7/RuJVN\nJKvfYROkE96q7uHvpLyAqUj7k3LDorVih5aWHq3s6bl0ZfL50yuFTxoLlKmSKZLhesis3+ebx+hM\nGnFeu9G2efi5sqi7gtXu4a+QvqOR812locukQoY1fRO+m4lo8AeAzUiaW3rxgvne8Fz6wC2WFsry\ncXn45neZTBMdenPzkyd/aSBPi2f5LBAnNsaBW0hELLpDUmpBb51Y9PC7yu93ZsapucH64TzR0Ng6\nXxwkKoXT9AaW+y3kKIoFZSJReWHj/tnlMniVUdHpyq5Sqc9bvT6nhPHsi4WE/mzs2NFgSAJd8iEN\nTFrYpux7xRxdcC6K40I0+AOAM7icjrmUrPXV8Sh6fsLo2Kr6Qryf4ku8SNPTbQunn2ea6IYuf/l7\nlGuw83F3n5draenRzCirc7eXarU3DCgjkbN0arWZgjKmSvtL01m2qlmIkh0kfbdWpg3E7bRsv1MX\nE598idyl2HvQ8nIZebjJZGjplFi5S+FYOj4VrBxLp0zeOYSWXBUhoctQ5KG6VSrT+R8HosEfAKPw\n8EOrMi9eLO+Vqo/54YcfYZOiZUwTtailuNjZC7h8qw/zJOYMFfvKzlTmVnML8szMMYMVpBpdPpGq\nxvzFvRTdv4pyB1ysnTO2PjFd3ejkJf57s8X40sY8F7tZ5dep6+Gbz+tT2TUcoxBZC3W+bC0bfY/f\n7HCNbxK4rEOZbUHImVe3kajGbhOwN8bwB/kzKQafyE3RC5GslbCxN2y6K3moxo+a5hP355pGAHNU\nr3c2QivFRiB8AZdNr4YbW86pllrziyQolM3KuQ/uWssqXHmqpBrzP555b3roSXjNertEM2YfZtz0\n67Fp9/t8N1+dephEB6y+8xnjDHvuINjDfmVwhWtGEXYpoyyXzaNrQbA9b1XzQKNANPhDAPdgclt1\nX4Rob4eyZXw+L0I/syR3DWIscyTZHHfffU+2k5F9VHnt+uXl5VIxM1tyU5b8l8Xu1bnnXkazpeRj\nzmbZcv5FMdRtZMb8d5JokWgyf2q1jjVhGnqfXCwPW65CMoNcnqlpkHLKKLeLzHeQ+0jdQfb7bslm\n7v743EP9eobNcHF1LCurEynbkdh2lOOO26uIBn9CkXPR3aJmoZ6jj4df/H2X8Xhb2QJwacNQyKbk\ns7PHqV6fU4yffeFSPUSdvsjpxZQZBU6nf3V1VWGWuJtlc7F2vTFLo7FoFdUyG7P7efhc+CaU5ZEX\nvPEy08XPLWSL+QwBHVK1fcp3SEK+YGVlhVn0ijpIVY12yDPtypdw1y7u5RHidt7ceev1OUrTWWq3\nb6Z6vePMOVTdxW0mosGfYPhuaUNZDK7P85WsupyuYIjoiUNZwVv01mWhzbHSl0v1NtVm3xxriT/e\n7MSVh5W65GKWlG3V1d2aytNXO3hxIRe1i5bOelHDf2oVqhjvhWye+yR18Mulnrukir3ZjJ5YsG4i\noEH1+vUbc6qP5YknnqRW61Yq6vAfp3b7AC0vLxsLkqqbZDN+PvF+kcdy7wz1e9Zo5DtP33CL2rvY\n9m7s2NGkXL57zunAlL1bk4Bo8CcAw4hVhn6H7fN+Hr6MaQvDLxuDC4Eyk3nBNdTu9XrG54TXeT3p\noQMxniJraWnpUUuv3VPGy3jxIt+oXW63Qzwz3cjY2iKqxqe4I8gbs3Ahgpzrfo5E4xtpbMykar5D\nupmAN5Ha46DRWGQXBy7GfObM0+zvRFW2rsOfy12LBUy23ZwvjI/PF+QSEy55BZ+QZnG8l7J52puN\n55JxTCiFudfrZbsYfVFLKU3nnQZ9FLmHYSEa/DFjVLHKYYxJpy7qDBFZ/FMMpZgLBGc8+eIcGR8X\nuvPFkIy+1Z61Ngjn6IgidqvnCZobhsdH48e2MJQ37pAyu0Vv3dYUpl7vkPAmiwngWm3WMha+0En3\nXjnP2dQdkj83lSKlDr+cV6GX0yDgRgIaG4qitrlSd3Bi12fKMpgLPC8lnd8zkyGm7jwHCbfY5L5X\nVlYm1qCXIRr8MSIkrjus8/l8J8fKsIUrOEpgo7FY6gUJD39PZtz3k6yqzUNGvQ2ja2Mt/cRP3Em6\nWiJHR5QwE7hPaQa7SzIkUqvNGKEWWxUrZ7jzCt4+CVaP6a3bkoCiHuEtZKuKlvOXn7NHgt2Uf1Zt\nSq7eV3PRy3WHimMxteBbrSOlIRtbItnM0eRUV90TFzs/OW+r1Gjc4titmAVOelGaPh5Oatm22/VJ\nTG8lRIM/Rtg8S2lYyxJwROFxfqkZb6MmhhaluLxe17jy4z5NwpPtah5aHoc2t/hC8Cv3hP0oqXmN\nQx6Tll6gru4oJB6KeYhO5xhxTd/X1tYsHv57smu5lXQPXBoOzgj1++6qaHPeywvlJGyLnhyLVDoV\n8ztn/U7fEIl0HkwWVk51NWUZiosjUGdZVbbkNic7YXt+y573MvbTJIdvOEykwQfwTgBfBfBHAB5m\nfj+yCdlM2IylKOqxx24lfJkZttitbvS5+H0ZhVGOQyYwa7UO/cIvvN9LCkGv2qzXRTUrV7cgWUui\nr2yT0vTW7EV/kPI+sy1nx6OwkIxMAHMhgyal6Y2kqkVyAm55WMfdaIYzGmfPnqOpqSbpSV7182fO\nPL2hH8S1a7QZI5vukM6rtzUfcc2li0UknxGX9INPEx39nqpCd43GPN1/v1vnP/QabPM4ieHYMkyc\nwQewA8AfA9gNoAbgJQC3aJ8Z4ZQMBl2quAy6hye28+YDv7y8bCStRFKtfGHgY7eC8aInUsuUFG04\ne/YcJUlKqn6KGtO1gWPA2DwmPg6/QCKGfcGrIpfzqG0JRrFzMI11u33Y6N2bpvPUbh+kIqNFDetU\nMY7HqV6fLRTu5NTCm7LF8XCBJeSqSeDmfZCdmg8jRQ0Pyu9y9WCwxc1dbS/lOZaWHg0ywKG1Efo5\nqzhH48YkGvy3A/h95f9Lupc/qQbf1hZPB/eyyf/bHvhWq1ieHeIJ8bHbJtXrbzaKoPJYtn9uQXz/\nLPkkDl0o2x7bmR8HghgTPsZOMo+4rmBiB1a8R4KeqTdwVxO3PD2VG68rr+Nzf1wVzrY5rmr8XPfM\nVrRFZHeMOIaOK26uLo5lonEhc112jYM4R+PEJBr8nwZwTvn/PwawrH1mZBNSFTZJWBvP1+V5mUU9\ns6THqEM9oTNnns7Gdyj7ezdJSp4+Po7CKHML3Nh7vR41GjcaxwD7aXl5OSjH4OqKJKiAJnPFxu0O\n2XLbYunCc3yk8Ls85FY0FLrnKkMiso+t2mvXBpfhzX/HyxPL+yNomvu87x9RWIjGZxdrY+k0GvNW\nvSGToSMW26WlR9hx8OfgcwMh9537vX2s9sV3ErFlDf7p06c3/nS73VHNjzdsTR/Onz+/8Rnfl6qo\nxcM30AhlEPR6PUrT/aQnSNVyeunJrK2tGTsCEWu3a7vbPPw0nTW6SXEeN5djUGl7eYJOJvSOkyuM\nVeYpc2OwKUOqnHuzbWIxd6B/t8w9tFpVe/b6e/hifrok2C3FZ4MT9dOfPZ8Qje8uttfrsaqxrdYB\nq95QcbHrE/AkAU2rVg+/4+PZPy7YFrCyMJfMhXDO0aTIKXS73YKtnESD/3YAf6D8f0uEdHw8fBff\nm6NBuhpoEPnpp0jkRpkXZdM9GT1h98QTT5b2ed2xo5HNwT6SGuhFb7xIdVR3CGUvbi4QJ7nXxepT\n3dC6GFD6GDgvzhajLTJy8iIq26JThdbnMrx5mGRXNtcioSuu6ybKi69mCUip1TpivX8qhdWnT63v\nLlZeO+fh1+uzVr2h4jEhEt3F8XB1GGVzze16uGdIb9giEueTJ4NswyQa/CklaVvPkrYHtc+McEqq\nQ2/6oHs/3ANaq81kYQozzklU7nXpSU/Xg2arYBQevSkopX6nz+6k3+/TysoKLS8v08rKSmkhj+m5\n8lvzdvtoFqbgk5+yfaPKVuK+k/NybZ5vsb6gGKN1sVdUVElA6veViyeLkNIciZDHDE1Pt2ltbY0x\nxi2q1zsOKQqxixLyAeVeu88uVkW+OOXS3a5eyPIY4cSYEt0ueYWy5u22OXaNhVv0Xe0nJ1VOQcXE\nGXwxJrwTwNcAfB3AEvP7kU3IoCiLb6oPqKhS1RN9C4bHWJbMDIlV66Jsp049lHkoB0gtfvJ5ucp2\nFMWXxSzk0XcIwpOXnPVi8i3f6eRl9PJl09lKU1NtWl9fN8bLeblcwxofDR7XAivvF1+aX0ysl91b\nHbZk/fLyMplSFceJ74qlUiP9vfYQD1+9PnX32u/zEs/cMb45hdA5lDBDSD3qdIoFa+ozlMuGlO8w\nJxUTafBLBzDBBt8H8uFYXV1l45zt9gHvGGBIsk0/P88/LxY92Y71ebD1xc1VyEOkStc+RnpZvf5d\nUsPGZgBrtTY98cSTpbsUV2zblcC23R897p+Lb5k5hyo8ble5v22XpHP+l5eXM1E0IqGF7++1l+1i\ndajPi369tkbs+lyOynM2k8R5S0vuGgRpwI8KrV/7pCAa/DHCxWTwfUgG4RLzsfP9lKazwS+XKwSh\nv/C2F1gsgDJ0Y3pc3DlsBlDI/u5jY+DNZs6cURcTXfnSlcAuTxSL+D5Qywzk9VSrzTAsj7DYrysv\nIK+D64qlLjLF6tRwr9231kRf/MoWfPUa1UV6lEYzZ68Vr9/WUtSVk1F3M67OZ+NENPhjBhfnDHk4\nuGIk36QRZ3Q4yVjbsb5FPrbjVOTGap/VWNm+j9Om5xpcSORhrXzhkYyLdvsgTU21qFabdSawuTHl\nC6iM+Z/IDOsjpCd3i+JfdvljDnKsrdYhY75dIZPi/c5DY3my3e61hxhennDgDulJhBaMDTJO2w5O\nCsrp3+Fyroo1BzInEs7vHzWiwZ8ArK+vbyQ6fTw83dAKETJ3Q2nueKJqC86wPTfeM26W6gip48mb\neswS8GbSdfHVXQLnWQvj9BQJMTczuSw18Dm9dXXLz2ng2EIrIeEBfe5braMFTST9vtp2Q/kOigjo\nU7t9YKMKVvXabQu6Gk5zjc9samNP2qvPh09Ct0z3xtfxsOVopKAcpwvEjc8MjZYvbuOSZYgGf8yo\nUhzEd3gqL+220Q+FkfokCf62u9l6/nkpWBbuudVqM1SvzxViuZxnvLT0iPc89vt9uvvue0jI9dpD\nGpyX1m4fpVZrb3ZuU33R1Z9X37qLMeghpmLyVHrAesK+jLJpCyn4hA9CdlD250zuCsxQmRwfF6IU\nz8lTBNSJ0waSMO9NviCVLQahITK+UnZ/tuA/ZT2WC0uaNQfuxa1qOG8YiAZ/jAi58fzLZHZ4soUE\nbOEbkexT+dt88wyJvNn4ieyYc8bDrRsu04M3+dVia23nXfts5bn5UWmatkR1s7kzU968jTjqZ70+\nx8pAm3IKXarXO1kDeH4cuQfMV8O6Qjp8vmLRGtJzJ+d5RUn7c7ZuzIv+rNqkL1otofuj7uC4PBUf\nctqnOQXF+Zd1BKG5LPM6uwSk1G7fErxL5uesTTYpjUHyboMiGvwxwtxi22+87WUSHql7sZDH69LA\nwP7M0A1WTCMSk/Nkq34tjp2XBbj//g9YDaDPLoibn1brEC0vLxs8fY5HX6xRKHZQsmnX592piFSu\nfq02S7Vax4j5+yx8Li9P0DxTKkpJp8T1WVULzNJ0Pgv75Z9pt4+y9QD25+yj7H1TKYm2xZRrZm/r\nW2AmlcX3cGwqtRq7jN/PYRAOP/ddXM2BjcgQPfxtZvBDk5TcQyIFvnxoa7lBU9vV7SQRyikaWq55\nBpHdGKSpjJnzyUfT0Jkeqc1Y2H5e/hLpGvZt0puP6C/j2bPnspdWbu2fLFwPZyBsceBm0+zfas7f\nJQJaXpXSxeelScAiAQuUJDLhyuUkVOPYyO61u2+A7TkTOxkzTKGHk7jFlHcU+I5XRMTSldVFzCax\nHFIApS5Sw0qcqiwd31zMZhdrRYM/BpSFH2zgHhKfTL/thRPhmPJkmut7Go0Fp/yDPvZGYw/ZYrm2\n+ChXHKO3H5THC4O9aBjBYns9e/FTXgvQZa+HS3qXcfVND7hLsrNWozFfaiBsz0u93smut9gOcGnp\nEXZhsVVz+z5nqu68y6vmjGhOh70tuzePWZ8Xlwfc7/etncf03QanlyQ1cMp2jJuByNLZJga/1zMb\neKfpocol92UPjoi767FfGd75CtVqHW9vgzMGPt5Kvy9kF/J4Mx/LtcdHi8Ux09Ntli0jFp+Pkggv\nqdd7PLteIlXegKNohi6sLmqsHo666653kY+MgQpbonl5edm6GA4SOuLuA/fz0Fi0qIruELCHBqnq\nrsLmyXMnptx12XyMwzCPCtHgjwFVStRt8OEt81TBosiU+lD7JEj1z7q2xjlvfK+x8PgkqzgNINVj\nly9skdtuY4vkSWWbtpA+Bz45BNsiwe+s7KEV24LOhVmee+45q+HLdzvXk4grh825bTwqfTOUdGDW\nS8xR1apu24LA70LV+L+7+5jtPOPeDQwL0eCPCK6HVXj40ss5TmXMGNc5yl44sxjoOEnKI2fgB6GJ\ncp81cwftYG9TJJx1j/0oCRqpTW0xT7zKJKoaK+/33eqhPnPM7UbU/9sToLJe4ByrJ8TNp/ydbAMJ\nvImAJt1117vYOop8of+ksfi5QlTqz/TQx513mrsT31i0yTDqk6g+blc2otzY+d3QAWq1jirnrc6M\n26zk6qgQDf4I4ON167HcKg+Sz5baTJgWwyiDFFEVXwazDmB9fd3i1TW9EpX2c0mqoMmZVg2QWiTE\nGWMRBzaZN+r1cuGwsmYi7nF3SA9NyfGVGRehiKmzdBoZDbTYyJ1X+9xf6MikP6dnz55TEqPHqZgY\n/TTZdqU+IY+i5lG+GHN8fH0O1R3k+vq6MzFq8/CLITfZb7g4HzrGSZ8cFaLBHzJ8vYJhZOl9Fw7/\n7a+9iMrtvZot3lxl6/V6x9D+119qW9KvWFTVJSC1il35JUKLCU9VQ8UWDvNNVKvjbrePZkamuADW\naqKE38ZMUY1LUZ54nYTw2XUkGuUUjzMLxYoLsj3cpBv1ndlCcp5E7L1I67WJrHHzLeL3c6STBGxy\nHnklueDx57ublIB91sWCe97znaZsMv9YaaFi9PCjwS9FiFcwjGRQ1T66/Fh5xg7HaiguNuZLkXdf\nMo2KalTzl/oIAU2q1a4jIRNhUvaKdQuD9xHNmSO5kJoKWzjsgQc+4LWzUkNmq6urNDXVIi6EJCUb\n8rnnE9p57ud9yj1v0NRUhzij5HIq+ET+YQJu1n4mG9H8MzJpvWF5J5FX6JCgvarnMAX7XM8Xl7/R\nwT3vMpdUpUHKVtC690E0+EPGML0Cn+TpIOfijtcZO66CFpsXnzcsIcVYCv74vffe5zy/S/isbJGp\nwrRwzXHu4V8g4VF/kur1jtb1yjy/TcJCNC4petDF3cIlEiEfQaHkPNj3ve/njO8A6lSvz7FVnbYY\nPZ/IXyC9RkKE325hztmkkyd/yes5U89bZGrJ7xL3VJ3DfLE1C/VUxlW7fTQoxFLFyRqGYzYpiAZ/\nyFhfX6cHHvgANRoLA3kFVatLud1EKNtB/XzZOWyUxGLIo0siSflpy0td9PZy+qR5PWJrnhqLjJ5s\n9Z3LsrnJFRBTUncetq5XtkU4j6mfy4zqMTJ3C+UJRb7r1D5K0+vZXQqHfN6LYwFOEddgRvDei0nz\nTuc2NtRng3oParVOpiO0n2z0zCoe/iCG2VfyeasjGvwhohheadDdd99T2bP38dx9PqcbO07psMzL\n9T2Hzs0XC4HPS+3n4RPJ5tgHDU9UT7b6jL9sISgmu00uO5drsC2QJjdehGyKlcTllEEbpVfsQOwM\nIn1OcqXOIwTM0I4dzY2qbV0R0zaHvgVM3PFpOusscFOfq0ZDFNIVY/h80V4V+qRvWNSFrbILiAZ/\nSLC9iD6SxzpC8gChBSo+Fb0h51DPpT/wZVWr6neLxGOTpqdFc26b1LMt2XrmzNPsC+dngM2xFY/j\n9X9seRnOsLti6mougasL0Bkpetcp4MHCuMoYRP0+r7rpqqXQxx6iXWO7B3rlruu5crF0fMkLHKrW\nxKjP+1bi6keDPyTYttqNxo3BD4GNWra8vGwVNfM1drpUb8iYbDFwF00uZLFwsXS475TJ1pMn77O+\ncLZFh1O/tO8+wqpVL168lHnQTQLeYnS6cuUSVD2Yen2OarWO9bqWl5c1tU57y0Z1TqvSDdWx2+iq\n5Ytgcf6G4Rn3ej2q1W4kVfG1VrvBK7Yf2pidyI/K7KOnMw5MlMEHcBrAdwC8mP15p+Vzo5uRivDd\navtCNZRTUzLZF7bl5D18QbPjtF5CQj1yjMKwiSRjrca3RvR9qUNefnWRKAvZSAZQo7FYyFP4hqra\n7aNUq3U2EqO2xiPqmKo0N1GvzewY5Ufv5WSEm02xMKp8e9e1l90HW9K3bBFUF+nTpz8ytJi5qE8w\n3721tbXSY0M9fPO5ManMwF5qt2+eSG9/Eg3+hz0+N6LpGAxlW+0qlbRCErf6ljN/ufmmILYYv79k\nQ9HDlLzyUFTdFnMS0+32Ubapt8r3ll6qqjaq5zcuXrxUkFU+efI+StPZDZXHU6ce2hiz6o0L6qHZ\nWJ3TSnLtznS9pUbjlg0jaavw9c2L2JQlw8gCRbrqE088yd4jOb4zZ56mNJ2nWq1YLVwlZq5CeOk6\n1XOfd41ASGN2HyqzD210XJhEg//PPD43oukYHLatdtUbP+iWU77cXJ9TW4w/TWdLK257vR6rjaMK\nk7lQZqR85isvxipKTAuJgbZhMG36+nfffQ81GkJATW1iXhxTV1t49f+rL/onSdev4ebFZVxNz1Pw\n3huNW0nkOPZYDbLq9XNa+FwxndxV+NwHM9wl6Kqu4ilR1cwVdYl5HMTTH4Y2lS9Lh3tWJZVZFNep\nbR0nrzJ3Eg3+NwC8BOB3AMxZPje6GRkShlWwMfiW0x4vtcf4P2oYcq6wKMST5ebGbHFoP5/PdYqx\nNEhUhM4Z8yZj2WUesJAYflQbU4+KC6/+fzl3shI1pAuYaVyFhy/1lsxkLsdd1+dndXWV3enYQ1f+\nXbhyBo3sp2wWyhWTqedJJNi5+codmDJ2ke13Li992Awa7t0etqM3Kmy6wQfwOQAvK39eyf7+SQC7\nACTZ534dwDOW76DTp09v/Ol2uyOepmoY1oM22JYzLJkmDMm6YbC4B1dw4uskPNvj5BOrthk6X6kC\n13UKr/phynXvU0rT4q6GP24fqdx/4Cil6SxTS1Dm4c9vnLtW61CjsWDVDCq7T6axPMQayzKDPDd3\ngqan2zQ93d6oMFU7MQ2SnHbJQstrzNtnlnv4rh2PT6iJ89LVHYZvnYIPbCwdGdoLZbSNCt1ut2Ar\nJ8rDL5wE2A3gZcvvRjQ9k4tBtpw+yTQ9xu+rkS+6RM1Sq3WglO7Z7/fZIp7Z2eO0tPRoUNm7PVYt\nBdEuEbCXVlZWjHh3uYcvkos6bVAvtjp16sGCUiVQNxLDw6hv4Ctd7R5+8bvz3rBpOk/33ntfZgBF\nuMfcyYgexa0W343K516qRXlcWKpWu5n0GH7ZzjRX/ly1Xrd9jou9FHyNvo9hto27jLU2LgrnRBl8\nAG9U/v1PAVy0fG5U83FNIDScxCUwywyWrote9mK4YrmyVaMaQw+5ThnXVlveid3GjPWlKxaF3UdF\nYa2nCsbGlSAtSi9coHrdLcjFjZ8rdpKQhjVNF6kY3nmTVUMo3z1wfQH0xa2RVb2qi8Mepzfsupcy\nbNbr9bKcAJ94XltbKzgwrh2PoICmlHftmvOSE+/1/BRRXddYZpgH3VFvdshn0gz+72bhnZcA/B6A\n6+YQpdMAAB4xSURBVCyfG92MDBnjKtmusm30PSZUsM2MmwtPT2q/CBXFahzttbU1mppqkBny2Gtl\njRBx/PzHCEip3fYX1jLZKifIxVaxzZFPoVQe3ukR8Gmn0mP++Qtk6tAUpSuAozQ11WQbh5fvHvJ7\nKcONd975ro1rGUxuO188bA18fHa7Pj0PfMdSdacmUbX+YZiYKIPvPYAtYvCHUbI9CEYRK/RNIqut\nAzmmSKdzmM6fP28tgPLRm8899ZuMMYV4cWr1aEi9gM0Y6S982S7Bx2Dkuj55oxM5XpucNGfEbeGr\n5eVlQ5653T5qJOD5HMghEnkGUzN/0PaZQkrjZmPhStNDVkOpzu+ZM08bY6qSH/LpilV2jdHDv4YN\n/jDbGFZB1WRV2SLhQxPlWxLyGjncS2CrFnWzXKSnKcIMw4zTquAonSLMIHrK6kVt+udV7r6NocQZ\n2mL4qE85TVOEeDiaJifkd++9fPiKZy+ZMhz2RL+8frOZO9dw3vd+5Nftl0wuirTNUL0+l4XDBKW1\nan6ozDD7PkfDYu9VRTT4I0IV/nwZfB+qqskqXyaEayGzbaMbjVspTWfZB92nWlT3sER89rg2v3sI\nqBkNUQaZS/XzNp66kD1eIL2q1jQcXWPuuMVN1kKoc1T0OrnYfDGJq5f/q/kBmy68LYFvSybPzByj\nYu7EvL5heLCioltSgO1dstyMI7Mjm3oct0MalWHeTJaOjmjwR4Rhe/i6MV5aesTKBKiSrArxalw0\nUde5XRo5oWEOsbDouurz1G7fUhoTDWVKuHjqnc5hJekpxiE592ZogPeAl5Yeya5lbzave0inuBbn\nxFTVVGma+cLUJZuYmM3ocJXLLsltvWLXJhttu9e+kAvuysqK87kPFbzLFy+TMDBOwzwqRIM/QoTw\n513gt9EtEhS3DpvkC01WhcYtbcloc3dRbB0YsvXlmnOrMNvWPVXqUZoJUDfFz+01fiWTWuCpiT4e\nfq02Q83mTmo2byazX22xiM2lqql6+MLgS/67EBOzsVq4EIrPYmvLSZT9fxBaoo/ch3mv3Iue+V75\nhwO3IqLBHzGGwdKxV8ReIGDBaIVHxMfR/QybnyG0QWWd6K0DXd4U9z3FmLW9+EuEVEScdmrK/cIW\ni4HcxlB+vjj3lwhobRRUlQmR6aEB6QF3OoepXu9kIms2r92UY5DGU+rSSEqqyv/33V3aDKgrmV11\ndxTK2tERktyWY0+ShtPh4sOCoujuWvLqVUSDvwXQ75v65UI6oE/AcWq3D7AGK2fKmK3vOJSxisq8\nc1fcONSb8t1x5AvDh0jPV3Dj9TWGKhOHSyqrYYWyeK8+DnlfWi1Ve8WMy+tyDPo8t9sHqVZr0+nT\nHzEkM3T+e7N52JDGcBlQPWQjDTxHobWF6sxzmMqSvrTEUL770tKjpQ4PHxYUi/Ek6d8ME9HgbwH0\n+/3sRVsgKWEgep92rR6+eqxvopdriqEbNc6Yy+NdBiTUm/L16Gw5g+npGarXRbhFNcI+xtBk1gwe\nl3YtILnommDe6FWufH7DnpD3mTsfA2oPJcr4fp/S9Caq13nNfvMcpsZQ2a4zlL4qj/MNaVYJC25l\nRIO/BVCsnJTiXKLPKhfbroLV1VXD+5IhheLLlpfq64a0TBvG15uyJQRthpZ7uUXs/4JhHHw8W+73\nrmShPM7WCEZdQIQ88I3GWNvtA0b4RD9WMph8EvI6E0ffbfkoY9r1ii6Q2vtWaAiZjB5uLn15+b6K\nrxxCSQs21tK1iGjwtwC4FydN5yu1T7RBGHxe+dJVqu9rSIns3pQaEuBe9LIdCs/7Vz1RQQvVufGc\n4bAZuUbjRqtWkKAN5o1gVNqgLZSlq3Ny99I2p0Kl1O69qrmSWm2WpqfbG3mTe+/95Y35lU1dbO0x\nuUVB8NpnmWdFcPH1XQI31z67oeJ5ZWU237fAfjxPHLAdc60xcjhEg79FMOqCDS5sVKt1NnqI5glU\nuxfvM8ZikrVFU1OtQhs/m8xCGfK4+JHMGHVIN7JqnN72gtsN9BHi1EDzHAJfGMQvIPtINI45Tq6k\nsW3XZManc445P34ZMuoaC2OjMb+xe5ELrxq35xYFQd3Ud1THCPgoG150GVM9bCM1eFw1B668gYTK\naBqmSuZWRzT4Wwgh8fgq3oosx2+3hfKl3tFJGGp3DNbHe9PZNyIBvZoZpKJnHqI1kifrGoZ3l6Z+\nPU7lPDSbO7PFo0HAKWWsRaqkrfS/3T5qoWbKBeTTVMaGcu2a5AInq0ilHj1XtJbrzpt1ALL9Yd4G\n8kZ2UeCbhuvXtMdaFOWaZ71jWJHN0yNdR19v2eiSMtgOXnsIosG/xjCo/KorudhsioIvmxfv84LZ\naI4iRLGTgOuIi737jl2M+bHMAB3KPOnHghNx/X6ffv7n35+N7QSpksuqwS/z8Im4UNb7SBWPC9GX\nUcMZnB49X7lr9/DN8NKsYWDdBUt6ta3fPXPvRPJYf5qaCxAn01Hm8asYl6DhJCAa/GsIIUwG13eY\n2+rii88Zdpn4kv1e/QSkzEIm4Y3zEgz6GDnGTj7mc5nx2mOVEXbBVNMUBomTXC4r/c+TiDLhnovH\n+dybfj+Xr263b9uYF1vIR9XxF1XAdXax4UTthPyyXzOafl9q4vOtJF2w15b0Nr5jZWUlW9D03Vox\n6d1oiHuszo0N4xY0HDeiwb+G4Eu1s3lCOvVSlwywvfi5Byu9dDe1LeeRHyCdGdRsHnaKbbl2MOaC\nZ9dPcSFX4TxAuWdP5JJcdrF0Bl2I+32eMmvbhanx8Dz8M2t0vOIpovkOyWcHUvXayjz8ZnMnE8vv\nUbt9WGsj2DV2ALb6hXELGk4CosG/hlD28oUaS6BGQIOaTTtdLYRuqR/n2zTb9/rUa6ya3OYNUVGY\nTP2sbxghREJX/04XZdb1vVxC1EYZbTaFXIOs2PWVig65NtdxXGtA2/1W6brC+PNzo2MUgoahGHde\nIRr8CcQgMUbby1dmLIu7A9nQ4wABszQ1ZfeCBi1PDzEWRXroKgGrTh5/6EuVhyj069lvqFdWyZWU\njcv2nS7KrO17Q8an5m2qzpttd+NzrGtRcj3PvV6PVlZW2LlZWVkxzjVuD3/Q/NowEA3+hGEYMUbu\nxfEpjBILQpdM6d0W6zEVjyu+RGU0OB/vkztG8N2lVyf6yA5D+14ylFqtvYZRSNN5Wltbs1R99gm4\n4Kx29h2bKzzDUWYH2QkNAnUeN8OIue5bcW6kqNwbrWMZlqBhKEZ9T3wRDf4EYZQeiG84RGyR93tt\nkdXjJGODE0XTX9iqRkK83LPa/LilJfQx2sJZYiFZIMHIaZMaw5bSCmbTkmJrw6WlR7yug0PZgqxT\nZl1zJnrAVtOskfNhW4z1eaxSNzFslkz+3BbVRm1jGQdLJ0QLaJSIBn+CMOoYo0/4ZH193arv7gLn\nhansErVytqqn0+v1KE1v1ebHLh6njsN1TsHdN1sBLi8vW8XTbH1Wqxb4+CzIPjuh4uIVPseqQZcd\no1z3LrRuYlQsGa4YbBwG1YZt6+ED+BkAfwjghwBOaL97BMDXAVwGcJfjO0Y6KePCZsQYfYxGzqI5\n6uWBu2KvwtNcIKm14tKPLwM/P+Uevsu7EgyYjuERy12N7dj77/8Ac4xf7qIsgVol4VyMae9Tdh/H\nvXcfZqiquGhw986mWcQh5PnW8wpl+YVhLZijxKir5X0wDoN/M4D9AL6gGnwABwF8GcA0gEUAfwwg\nsXzHiKdlfBhXjFGH78vBhUrsTJd+Vurux/PWIZQu95CozN2beZeplSqpXovNGOQc+SLtsVabZeL1\n+bFc0ZMPO8mniUeoUSpWrMp6gDy/ADSdITmJ4uJmdozi7l29PuclaEbkv4PNmUOiOX29fpBsfXu5\n41xtNMeZMCUaLME9DIwtpAOgqxn8JQAPK///fQB/33LsCKdk/NgqlYA2Y8gVbcmGLTqtjmNelHtx\nXRIsnU96J0vL2UuyuEck/tTQjO1YH2ldPR5uWzyqep7md3ZJFFr5JXjV78k1k3gP33bvfBeptbW1\nUg/fTR7g6bH6dXChRX2OqtRnDAPjXngmyeD/NoD3Kf//HQDvsRw7wimJ8IUt3MHx64FWIdlYNZE7\njLCHLZTiEtqyHeuS1uWkjfX5klWiVQ0AV8XbaCxSvT7rleDVx6ny4W1qmmWsGdccC2noJomwE9+F\nSsyRucNQ+/aGxOZtlGO1Anszwj2TEMcficEH8DkALyt/Xsn+/knlMwMZ/NOnT2/86Xa7I5+oCBOu\nB9ilARPyPbbPD/vlrEITdY3Hdk2CTSKF47qGxxtqAGxVzr67Bts4dQXN0IQvv4vKPexarUNra2uO\n8VTz8N3XaH6numsZtdc9DqZOt9st2MpJ8vD1kM4fbNeQzlaCb6WnCzYN+rLYvAtVFwVdXqJMe90G\n7poajT0ZA0rUEExNNQ3WUSh90txJ2ZlCeiJU/l8fp68aZdlY1DxJiKGTu6Y0vYHUGL7atzcUOXWz\nmEMQVGI/CZFBcc16+F5fIgz+W5X/H8qStnUAe7Zr0nazMYx8QZUtvv4Z03D58es5cKEUn+8pjoPv\n7OULPrbOqT5W9/A5Q8q18VPnRCZCpZwyT7U01SirLNoqE8rX0OU1HaJhy5kzT7MsnSoLOpdoFz2f\nw8XfqmLcTJ1xsHTeDeDbAF4D8BcAfl/53SOZod+WtMzNxqiVA0MSVKJYqEWyKQhwydq0PJSep+cP\nbChKN+w0DEMVETb5cuea8+ou5igBT5JsFcgVrbnga0h9QxpinKaCpo8B5Mai6uj7GDpfaqVe2xFi\nNPVxDFIXUhXjpIfGwqttilFz/kOMkfTg9MYo+ufLqmVtss4qQ8hvp3GBRIerPBHK6en4zoNbmbKf\n/bmeWq29Axsw7lhXIrTdPrphlG3jdDGPbGPRi7Z82Dw+1cZibMXajioxfY4wME5+/GYhGvxtilFX\n9frEbXUDLiUMbPmAsgSxrdzf1m+Vw8WLl7LOXsVEaNWEof7dIlxhNg3RpYEHMWDc7+2JUHP3Mwif\nXdI7qyThy+SebQvmMEIw4/S6NxPR4G9TjNvDD+Wkh1BAZTGQKM4K8wRtiVDRUMUd3pDGTm8HyMWe\nZSih3T5KIpR1iWwLo89c+1RPC03967Lrcc9NCPPI9165cgtli34x3CZ3Xn47t4gc0eBvY4y6qpfz\nFF2hlzJjyhkb2/esrq5uxHpDtuo8Y0iGd/JzcuEMYVAFA6dW6xR6Aru84bzYqdwbVo9VFw6f/q55\nyGwlu+dhvYN9DXl4bqF80e/3dYG7BQLS0tzMdvHcfREN/jbHqKt61RduUKVF2wJStpMI5dRzHn6n\nc7jQaFs1rvwxc8YOqoyZoiYSufJ73cgLdonfOYrG2kxKV939+FyTTm+tsuj3+2bXr1otr5bl7vO4\nq1onEdHgR2wKOGMRosOifo/txR5W0s1mgG2eeK/XM5QaRX5kv5cxU6/r7NlzmSfbImDfRn9cla6Y\nx/97JPIMfgazOP9PkW8bQxWuymLunLK/rqRZ3nvvfRtGuNGYN4y434JVvFZfPacY+okGP2KTIITP\nirREvX/tINvvYW/d9e8L5ZmHePjqOTnZ5UZjwVhshIe+HuSp++4kbGPTjbdPkxs+H/KY4qV3vBZr\nV/gnJNQ3KXLJ40I0+BGbgrIk8aRvv8s8xjyGL1Q8RQzfzjriIHYKN5NOnWw2D2c/V3cQRwg4TyEN\nx+V12EJstirpixcvZQtOk1y0We56uPaXomNZf8MIu5rWq+B2ciHJ/OjhR4Mf4YFheM+5tLHUaN9J\njcZicCXmOFEWOvJh6eif1xk8/h5+kwBRNXvy5C8F3x9fmmsedvkQiTDTCXIVxunn4CSkgUOkJsEH\noaD6XMd24Nf7Ihr8CCeG5XkXueA9Ujnt4xCVqophhY5s83rx4qUsmd0iYC8Twzc5/FWqgP094wsE\nyIU6XPqCk5CWSfBhGeFh6DltF0SDH2HFsD3vck36zffwx2EQfJhFNpbO+fPnM3aOykcPrwL2p7n2\nSfSK1ZPS/uJ2eqL37NlzI1E7HWdjka2CaPAjrHB5gcNOrg66/a5iuMeVNxhkR8Pz0TtUpQrYl+aa\nVx5XX5BHbZBD7+V29fyjwY+wwkWlHMRI2l62qi9hFcM9yK5iUGMx6Ll1KqNgBFWTGPCluQovfZ5a\nrSOV7ruUJ240bqykSVR2DSHzOekEgVEiGvwIJ/SXv1gsFd4qbtgvW1XjWdXLHtb4q+5o+Erg4UsM\n6AuBZOq02zd7KY/q37Vjh5SCFsqsO3Y0hjbWkHu5VQgCo0I0+BGl4Csj81Zx9fqcl6zvKF62qoa7\nyliqHjNIrwCfMfjKP1fFoPdtZWXFCAkBTVpZWdn08W0lgsAoEA1+hDeKTBv/TksSo3jZBjFGoV52\n6PhHFTrQx13WPpIrbAtZbAa9b8vLy6RXHQP7aHl5Oei6XfC9l9HDjwY/IgAyFmtKKx+lNJ0duofs\nO6aqCd8Qw+cafwg/fBjwGbe64Kg6QJxWfdXr9sGolVnVcVYt4NouiAY/Ihjr6+tM4nAndTqHvWPg\nw37ZNot1wY2f8+THHToQ7fxmSW1VKBg966QXdvkY70Hv26iVWUMRWTrR4EcEgCuoGZTlEvoSjuul\n1UMjXEGZT+eoUV2L2IXNZ7uwnZRr7R8nIcdQnRI6yBhHrcwaUY5x9LT9GQB/COCHAE4oP98N4H8A\neDH78wnHd4x2ViK8EKKcqEMaD6l97qvrLjGM+HjVpKkuqiYag+8kKTsgJSN8vWJVCTO0ry03PjOp\nKxek6h5+xLWBcRj8mwHsB/AFxuC/7PkdI5ySiBAMUvAk1DOblKY3GjHeMm940Ph4lQWDO2Ztbc0Z\nny6bH95AlyfAbeBpm/tperpNtVon6zfboXp9blvGsLc7xhbSAdBlDP4rnseObEIiRgvewM0TcKt3\nmCGk85ItdDQMSmatNsMmsJvN8lyGei2comRZAjxknFJrpypLJ+LaQRWDvwOjw2KSJF9KkqSbJMmP\njvA8EWPClStXUK8vAjia/eQogEUA3wbwcvazl/H669/E4uIi+x2Li4v4/vevOD//7LMr2L37Ftx5\n5wPYvfsWPPvsinMMtdpuXLlyJWDcb8Lrr/8Q3/veZwD8t8JYgD+3jp2/lj/Vjv8OarUbneOxYdeu\nXTh58h8DeDuAAwDejvvu+3kcPHgQu3btwtve9jbs2rWr8O+ICCfKVgQAn4N4cuWfV7K/f1L5jO7h\n1wAsZP8+AeBbADqW79+EtTBiFLDHmMN03csUEsvEyQb38C+Q6F9LlBeh7ac0DS+AGiQBbh9nl3RV\n0ogIVPDwpz0WhDsrLCKvA/jr7N8vJknyJxAuyovc53/t135t49933HEH7rjjjtBTRowBu3btwjPP\nfAInT/4YgDfjtdf+BI3GdUiS/wv/8l9+DCdOHMPi4mKp5/ne996Dd7zjx3HlyhV0Oh1897vfxdWr\nV7Fr164Nb/y110wPXnq3cgy12m68/vo38cwzn3CeUz/m+9//U/zd3xG+//2XAdwD4Dqk6U/hy1/+\nIg4ePBg0J/fffx8A4KGHfgW12o344Q+fKh2PDfm137HxM/XaI7YXnn/+eTz//PODfUnoCsH9gfDw\n36r8/+8B2JH9+yaIPf685diRrYARmwOdpVPVA+UYLr4e/KAsnWHXFAwjrr7dK0kj3EAFDz8Rx1VD\nkiTvBvDbmYH//wC8RETvSpLkPQA+CuD7AP4OwONE9B8t30GDjCHi2sDVq1exe/cteO21LkRs/XkA\n78SZM7+B66+/HidPfrDgwb/3vfeMZAzdbhevvvoq3vGOdwR796PAs8+ubMq1R2w9JEkCIkqCjhm3\nsY0GPwIAXnjhBfzET9yP//7fXwSwAuCDEH7Et3H27Mfwnve8G1euXPEKEVXFhz70T/Dxj58DcAOA\nb+PkyZ/D/ff/8kjP6YOrV68Wwl3jHk/EZKCKwR9KSGeQP4ghnQhSe6Z2SRdzS9Py9nuDwtSIke37\n/BLPo8Z21n2P4IEJo2VGRHhj165d+NjHfgvAOyE8+zxJW68vVqI1hqDX60F49kcBXAXwFIAv4rvf\n/TJee62Lkyc/iKtXr450DDZcvXoVJ09+EK+91sXf/M2Xxj6eiK2LaPAjJgb3338fzpz5Deg8/h/8\n4FveXPiquP3225XzXkFu/AEfbv8oUaXWICKCQzT4EROFX/mVD+Ps2Y8hTf8XzMwcR7P5Y5VpjSE4\nePAgTp26D6LI6R4AfwTf4rFRw6c4LSLCBzFpGzGRkInKzU5QXr58Gb1eD1ev/iUef/zJiWHHRLZO\nhI7I0omIGCLGtehslfFEjBfR4EdERERsE1Qx+DGGHxEREbFNEA1+RERExDZBNPgRERER2wTR4EdE\nRERsE0SDHxEREbFNEA1+RERExDZBNPgRERER2wTR4EdERERsE0SDHxEREbFNEA1+RERExDZBNPgR\nERER2wTR4EdERERsEwxk8JMk+a0kSS4nSfJSkiT/PkmSWeV3jyRJ8vXs93cNPtSIiIiIiEEwqIf/\nWQC3EtExAF8H8AgAJElyCMA/AnAQwLsAfCJJkrBmuxOG559/ftxD8EIc53ARxzk8bIUxAltnnFUw\nkMEnos8T0d9l//0igLdk//6HAC4R0Q+I6ArEYnD7IOcaN7bKQxDHOVzEcQ4PW2GMwNYZZxUMM4Z/\nL4D/mP37eogGoRJ/lv0sIiIiImJMmC77QJIknwNwnfojAATgnxPRc9ln/jmA14no2ZGMMiIiIiJi\nYAzc8SpJkvcDuA/AjxPR97KfLQEgInoq+/8fADhNRP8vc3xsdxURERFRAZva4jBJkncCeBrA/0xE\nf6n8/BCACwD+PkQo53MA9sdehhERERHjQ2lIpwS/DaAO4HMZCeeLRPRBIlpPkuTfAlgH8DqAD0Zj\nHxERETFejL2JeURERETE5mBslbZbpWgrSZKfSZLkD5Mk+WGSJCeUn+9OkuR/JEnyYvbnE5M4zux3\nEzOfKpIkOZ0kyXeUOXznuMckkSTJO5Mk+WqSJH+UJMnD4x6PDUmSXEmS5CtJknw5SZLeuMcjkSTJ\nM0mSvJokycvKzxaSJPlskiRfS5JkNUmSuXGOMRsTN86Jey6TJHlLkiRfSJLkvyRJ8kqSJA9mPw+b\nUyIayx8A7wCwI/v3bwL4P7N/HwLwZYhw0yKAP0a2ExnTOG8GsB/AFwCcUH6+G8DL4xpXwDgPTtJ8\namM+DeDD4x4HM64d2TztBlAD8BKAW8Y9LstYvwFgYdzjYMb1owCOqe8IgKcA/Gr274cB/OaEjnPi\nnksAbwRwLPt3B8DXANwSOqdj8/BpixRtEdHXiOjrEHRUHRNTPewY509hguaTwcTMoYLbAXydiL5J\nRK8DuAQxj5OIBBOoiUVEawD+WvvxTwH4VPbvTwF496YOioFlnMCEPZdE9F+J6KXs398FcBnCZgbN\n6aQ8KFu1aGsxSZIvJUnSTZLkR8c9GAsmfT7/9yys9zuTsMXPoM/ZdzBZc6aCAKwmSfJCkiT3jXsw\nJXgDEb0KCAMG4A1jHo8Lk/hcAgCSJFmE2JV8EcB1IXM6KEunbGBbomjLZ5wM/hzAjUT011nM/PeS\nJDmUrb6TNM6xwjVmAJ8A8FEioiRJfh3AvwBwcvNHuaXxI0T0F0mS7IJgy13OvNatgElljEzsc5kk\nSQfAvwPwEBF9l6ljcs7pSA0+Ed3p+n1WtPUPAPy48uM/A3CD8v+3ZD8bGcrGaTnmdWRbQSJ6MUmS\nPwFwAMCLQx6ees7gcWIM86kiYMz/CsCkLFp/BuBG5f+bOmchIKK/yP6+miTJpyHCUZNq8F9NkuQ6\nIno1SZI3AuiPe0AciOiq8t+JeS6TJJmGMPb/hog+k/04aE7HydJ5J4D/A8A/pKxCN8N/APCzSZLU\nkyTZA2AfgElhH2zE9ZIk+XtJkuzI/n0TxDi/Ma6BaVDjjxM7n9kDKvEeAH84rrFoeAHAvoyJVQfw\nsxDzOFFIkqSVeXxIkqQN4C5MzhwC4jnUn8X3Z//+BQCf0Q8YEwrjnODn8l8DWCeijyk/C5vTMWad\nvw7gmxAe8YsAPqH87hEIlsRlAHeNOTv+boh47msA/gLA72c/lw/CiwD+M4B/MInjnLT51Mb8uwBe\nhmDB/B5EPHLs48rG9k4IJsTXASyNezyWMe7J5u7LAF6ZpHECuAgR9vwegG8B+EUACwA+n83rZwHM\nT+g4J+65BPAjAH6o3O8Xs2d0Z8icxsKriIiIiG2CSWHpRERERESMGNHgR0RERGwTRIMfERERsU0Q\nDX5ERETENkE0+BERERHbBNHgR0RERGwTRIMfERERsU0QDX5ERETENsH/D13LH3o+oKq/AAAAAElF\nTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f6b1ef33890>"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Please get context vectors and complete the tsne transformation of these vectors\n",
      "### CELL TO COMPLETE (~ 4 lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3.2 ) Show output probabilities (sigmoid output) for each word of a random review on test data\n",
      "\n",
      "The objective of this subsection is getting predictions of each word added in the sequence. This type of analysis increases the interpretability of the RNN decision. To identify when the model changes the decision for example. \n",
      "\n",
      "- Get a random review on test data with less than 30 words (count the number of non-zeros entries because padding is indexed by 0 element)\n",
      "- Iterate until find first random review with less than 30 words\n",
      "- Converts the numpy sample in a list of integers without padding\n",
      "- Show the raw text of the review (use function *indexes_to_text*)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "max_words_constraint=30\n",
      "non_zeros_indexes=X_test.shape[1]\n",
      "\n",
      "# Get a random review with less than max_words_contraint words\n",
      "while non_zeros_indexes > max_words_constraint:\n",
      "    id_random_review = random.randint(0, int(X_test.shape[0]))\n",
      "    non_zeros_indexes = len(np.nonzero(X_test[int(id_random_review),:])[0])\n",
      "    \n",
      "# Create a list of non-zeros elements for remove padding\n",
      "random_review_sample = list()\n",
      "for i in X_test[id_random_review,:].reshape(-1).tolist():\n",
      "    if i != 0:\n",
      "        random_review_sample.append(i)\n",
      "print(indexes_to_text(random_review_sample))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 3.2)\n",
      "\n",
      "- Add words progressively (get one word per time and creates a new sub-sequence containing past words)\n",
      "- Create sub-sequences of words and add padding for each one of these sub-sequences (Hint: use function *sequence.pad_sequences(seq, maxlen=maxlen)*)\n",
      "- Get the sigmoid output and print it (Hint: use *function get_activations(model, id_layer, X_batch)* on each subsequence)\n",
      "- Create a function *get_predictions* and print the conditional probability of positive prediction given the subsequence\n",
      "- Create a plot with that shows the evolution of predictions (a time series) during the time"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.preprocessing import sequence\n",
      "\n",
      "# Get predictions of each time for a review sample\n",
      "def get_predictions(model, review_sample):\n",
      "     ### CELL TO COMPLETE (~ 7-15 lines)\n",
      "                       \n",
      "get_predictions(model, random_review_sample)\n",
      "print('Real label {}'.format(y_test[id_random_review]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3.3 ) Create your own movie review and test it with predictions of your trained model\n",
      "\n",
      "Question 3.3)\n",
      "\n",
      "- Generate your own review\n",
      "- Lowercase all words o the sentence (Hint: *.lower()*)\n",
      "- Use a tokenizer or a simple split for separate words (Hint: *.split(' ')*)\n",
      "- Excludes words that are not in vocabulary\n",
      "- Replace words by indexes\n",
      "- Get the prediction result for each word of your review (Hint: use the function *get_predictions* created in the last exercice)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# You can modify this text review as you want\n",
      "#text_review = 'Quite simply, the finest gangster film ever made. No doubt about it, this a spectacular viewing experience'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CELL TO COMPLETE (~ 8 lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 4) Transfer learning of pre-trained FastText word embeddings to improve results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Question 4.1) What are pre-trained word embeddings? How they are learned (unsupervised or supervised way)?\n",
      "\n",
      "Question 4.2)\n",
      "\n",
      "- Download text pre-trained FastText (Facebook research) word embeddings \n",
      "\n",
      "[English vectors](https://fasttext.cc/docs/en/english-vectors.html) \n",
      "[FastText project](https://research.fb.com/fasttext/)\n",
      "[Pre-trained vectors](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md)\n",
      "\n",
      "- Read and load the text file and extract the dense vector from each word\n",
      "- Saves only words-vectors of IMDB vocabulary\n",
      "- Create a random normal matrix with dimensions *max_words* and *embedding_dims* \n",
      "- Associate extracted vectors using IMDB word indexes\n",
      "- Copy extracted vectors in the indexes of the created matrix\n",
      "- Create the LSTM model with  *Embedding* layer and regularization\n",
      "- Initialize the weights of *Embedding* layer with created matrix values\n",
      "- Compare t-SNE results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### CELL TO COMPLETE (~ 34 lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}